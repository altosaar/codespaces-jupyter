{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick review from last lecture\n",
    "\n",
    "* We saw examples of continuous and discrete functions\n",
    "* We took their derivatives\n",
    "* We plotted these\n",
    "* We used an example from Wikipedia to study wheat yields with a logistic (or sigmoid) function model\n",
    "* We ended with a prescriptivist look at logistic regression from a \"canonical reference\" according to GPT-4, https://www.utstat.toronto.edu/~brunner/oldclass/2201s11/readings/glmbook.pdf \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's lecture \n",
    "\n",
    "* Taking a prescriptivist stance involves reducing autonomy, limiting our thinking and the symbols we use to communicate concepts very clearly and precisely to aid learning. \n",
    "* The risk is that we avoid thinking of the controversies involved: https://www.jstor.org/stable/3541653 (from Ismael), https://www.colorado.edu/amath/sites/default/files/attached-files/vallverdu08.pdf\n",
    "\n",
    "* Logistic regression recap\n",
    "* Embeddings from the perspective of logistic regression \n",
    "* Embeddings from the perspective of linear algebra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: what does \"expected value\" mean in the Mcullagh and Nelder book and how does it relate to logistic regression?\n",
    "\n",
    "* The expected value of a random variable is the sum of the probability of each possible outcome of the experiment multiplied by its payoff (\"value\").\n",
    "* For example, if we roll a fair six-sided die, the expected value of the die roll is 3.5, because the average of all the numbers that come up is 3.5.\n",
    "* The expected value is also known as the expectation, mathematical expectation, EV, average, mean value, mean, or first moment.\n",
    "\n",
    "The LaTeX formula for the expected value is:\n",
    "\n",
    "$$\\mathbb{E}(X) = \\sum_{i=1}^n x_i p_i$$\n",
    "\n",
    "where $X$ is the random variable, $x_i$ is the value of $X$ for the $i$-th outcome, and $p_i$ is the probability of that outcome.\n",
    "\n",
    "* The expected value of a random variable is denoted as $\\mathbb{E}(X)$ or $\\mu_X$.\n",
    "\n",
    "As an example, this formula can be used to calculate the expected value of rolling a fair six-sided die:\n",
    "\n",
    "$$\\mathbb{E}(X) = \\sum_{i=1}^6 x_i p_i = 1 \\cdot \\frac{1}{6} + 2 \\cdot \\frac{1}{6} + 3 \\cdot \\frac{1}{6} + 4 \\cdot \\frac{1}{6} + 5 \\cdot \\frac{1}{6} + 6 \\cdot \\frac{1}{6} = 3.5$$\n",
    "\n",
    "The expected value for an un-fair die can be calculated similarly:\n",
    "\n",
    "$$\\mathbb{E}(X) = \\sum_{i=1}^6 x_i p_i = 1 \\cdot \\frac{1}{8} + 2 \\cdot \\frac{1}{8} + 3 \\cdot \\frac{1}{8} + 4 \\cdot \\frac{1}{8} + 5 \\cdot \\frac{1}{8} + 6 \\cdot \\frac{3}{8} = 4.25$$\n",
    "\n",
    "As another example, the expected value in roulette can be calculated as follows:\n",
    "\n",
    "$$\\mathbb{E}(X) = \\sum_{i=1}^n x_i p_i = 0 \\cdot \\frac{1}{38} + 1 \\cdot \\frac{1}{38} + 2 \\cdot \\frac{1}{38} + \\cdots + 36 \\cdot \\frac{1}{38} + 37 \\cdot \\frac{1}{38} = ?$$\n",
    "\n",
    "* The expected value of a random variable is a key aspect of the probability distribution of the variable.\n",
    "* It is a measure of the \"center\" of the distribution.\n",
    "* The expected value is the value that one would \"expect\" to get (or that we would get) if we repeated the experiment many times and took the average of the values obtained.\n",
    "* More formally, the law of large numbers states that the arithmetic mean of the values almost surely converges to the expected value as the number of repetitions approaches infinity.\n",
    "\n",
    "## Background: probability mass functions\n",
    "\n",
    "The probability mass function (PMF) of a discrete random variable $X$ is a function that gives the probability that $X$ is exactly equal to some value. The probability mass function is often the primary means of defining a discrete probability distribution, and such functions exist for either scalar or multivariate random variables whose domain is discrete.\n",
    "\n",
    "## Background: probability density functions\n",
    "\n",
    "The probability density function (PDF) of a continuous random variable $X$ is the derivative of the cumulative distribution function (CDF) of $X$.\n",
    "\n",
    "## Background: cumulative distribution functions\n",
    "\n",
    "The cumulative distribution function (CDF) of a random variable $X$ is the probability that $X$ will take a value less than or equal to $x$.\n",
    "\n",
    "## Background: domain\n",
    "\n",
    "The domain of a function is the set of all possible inputs for the function. For example, the domain of $f(x) = x^2$ is all real numbers, and the domain of the square root function is all non-negative real numbers.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of a probability mass function for a discrete random variable\n",
    "\n",
    "An example of a probability mass function is the binomial distribution, which gives the probability of obtaining exactly $k$ successes in $n$ independent Bernoulli trials with probability $p$ of success on each trial. The binomial distribution's PMF is:\n",
    "\n",
    "$$f(k;n,p) = \\Pr(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\n",
    "\n",
    "for $k = 0, 1, 2, ..., n$, where $\\binom{n}{k}$ is the binomial coefficient, hence the name of the distribution.\n",
    "\n",
    "We can plot the binomial distribution's PMF for different values of $n$ and $p$ using altair:\n",
    "\n",
    "```python\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def binomial_pmf(k, n, p):\n",
    "    return np.math.factorial(n) / (np.math.factorial(k) * np.math.factorial(n - k)) * p**k * (1 - p)**(n - k)\n",
    "\n",
    "k = np.arange(0, 21)\n",
    "n = np.arange(1, 11)\n",
    "p = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'k': np.repeat(k, len(n) * len(p)),\n",
    "    'n': np.tile(np.repeat(n, len(p)), len(k)),\n",
    "    'p': np.tile(p, len(k) * len(n))\n",
    "})\n",
    "\n",
    "df['pmf'] = df.apply(lambda row: binomial_pmf(row['k'], row['n'], row['p']), axis=1)\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    x='k',\n",
    "    y='pmf',\n",
    "    color='n',\n",
    "    column='p'\n",
    ")\n",
    "```\n",
    "\n",
    "## Example of a probability density function for a continuous random variable\n",
    "An example of a probability density function is the normal distribution, which gives the probability density of observing a value $x$ from a normal distribution with mean $\\mu$ and standard deviation $\\sigma$. The normal distribution's PDF is:\n",
    "\n",
    "$$f(x;\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$\n",
    "\n",
    "for $-\\infty < x < \\infty$, where $\\pi$ is the constant pi, $e$ is the constant e, and $\\sqrt{2\\pi\\sigma^2}$ is the square root of $2\\pi\\sigma^2$.\n",
    "\n",
    "We can plot the normal distribution's PDF for different values of $\\mu$ and $\\sigma$ using altair:\n",
    "\n",
    "```python\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def normal_pdf(x, mu, sigma):\n",
    "    return 1 / np.sqrt(2 * np.pi * sigma**2) * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "df = pd.DataFrame({'x': x, 'y': normal_pdf(x, 0, 1)})\n",
    "alt.Chart(df).mark_line().encode(x='x', y='y')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "factorial() not defined for negative values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     13\u001b[0m p \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0.1\u001b[39m, \u001b[39m1.1\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[1;32m     15\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m     16\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mrepeat(k, \u001b[39mlen\u001b[39m(n) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(p)),\n\u001b[1;32m     17\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mtile(np\u001b[39m.\u001b[39mrepeat(n, \u001b[39mlen\u001b[39m(p)), \u001b[39mlen\u001b[39m(k)),\n\u001b[1;32m     18\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mtile(p, \u001b[39mlen\u001b[39m(k) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(n))\n\u001b[1;32m     19\u001b[0m })\n\u001b[0;32m---> 21\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpmf\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: binomial_pmf(row[\u001b[39m'\u001b[39;49m\u001b[39mk\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mp\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m alt\u001b[39m.\u001b[39mChart(df)\u001b[39m.\u001b[39mmark_line()\u001b[39m.\u001b[39mencode(\n\u001b[1;32m     24\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m     y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpmf\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m     color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m     column\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/datathinking.org/lib/python3.11/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/datathinking.org/lib/python3.11/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/datathinking.org/lib/python3.11/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/datathinking.org/lib/python3.11/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     13\u001b[0m p \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0.1\u001b[39m, \u001b[39m1.1\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[1;32m     15\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m     16\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mrepeat(k, \u001b[39mlen\u001b[39m(n) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(p)),\n\u001b[1;32m     17\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mtile(np\u001b[39m.\u001b[39mrepeat(n, \u001b[39mlen\u001b[39m(p)), \u001b[39mlen\u001b[39m(k)),\n\u001b[1;32m     18\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mtile(p, \u001b[39mlen\u001b[39m(k) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(n))\n\u001b[1;32m     19\u001b[0m })\n\u001b[0;32m---> 21\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mpmf\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: binomial_pmf(row[\u001b[39m'\u001b[39;49m\u001b[39mk\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mp\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m alt\u001b[39m.\u001b[39mChart(df)\u001b[39m.\u001b[39mmark_line()\u001b[39m.\u001b[39mencode(\n\u001b[1;32m     24\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m     y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpmf\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m     color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m     column\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mbinomial_pmf\u001b[0;34m(k, n, p)\u001b[0m\n\u001b[1;32m      7\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(n)\n\u001b[1;32m      8\u001b[0m p \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(p)\n\u001b[0;32m----> 9\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mfactorial(n) \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mfactorial(k) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mfactorial(n \u001b[39m-\u001b[39m k)) \u001b[39m*\u001b[39m p\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mk \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m p)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(n \u001b[39m-\u001b[39m k)\n",
      "\u001b[0;31mValueError\u001b[0m: factorial() not defined for negative values"
     ]
    }
   ],
   "source": [
    "## COpilot -- FAIL\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def binomial_pmf(k: int, n: int, p: float) -> float:\n",
    "    k = int(k)\n",
    "    n = int(n)\n",
    "    p = float(p)\n",
    "    return np.math.factorial(n) / (np.math.factorial(k) * np.math.factorial(n - k)) * p**k * (1 - p)**(n - k)\n",
    "\n",
    "k = np.arange(0, 21, dtype=int)\n",
    "n = np.arange(1, 11, dtype=int)\n",
    "p = np.arange(0.1, 1.1, 0.1)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'k': np.repeat(k, len(n) * len(p)),\n",
    "    'n': np.tile(np.repeat(n, len(p)), len(k)),\n",
    "    'p': np.tile(p, len(k) * len(n))\n",
    "})\n",
    "\n",
    "df['pmf'] = df.apply(lambda row: binomial_pmf(row['k'], row['n'], row['p']), axis=1)\n",
    "\n",
    "alt.Chart(df).mark_line().encode(\n",
    "    x='k',\n",
    "    y='pmf',\n",
    "    color='n',\n",
    "    column='p'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def binomial_pmf(k: int, n: int, p: float) -> float:\n",
    "    return np.math.factorial(n) / (np.math.factorial(k) * np.math.factorial(n - k)) * p**k * (1 - p)**(n - k)\n",
    "\n",
    "binomial_pmf(3, 5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'factorial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39m# calculate binomial PMF \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m x: \n\u001b[0;32m---> 12\u001b[0m     y\u001b[39m.\u001b[39mappend((factorial(n) \u001b[39m/\u001b[39m (factorial(i) \u001b[39m*\u001b[39m factorial(n\u001b[39m-\u001b[39mi))) \u001b[39m*\u001b[39m (p\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mi) \u001b[39m*\u001b[39m ((\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mp)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(n\u001b[39m-\u001b[39mi)))\n\u001b[1;32m     14\u001b[0m \u001b[39m# create Altair chart \u001b[39;00m\n\u001b[1;32m     15\u001b[0m chart \u001b[39m=\u001b[39m alt\u001b[39m.\u001b[39mChart(pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m: x, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m: y}))\u001b[39m.\u001b[39mmark_bar()\u001b[39m.\u001b[39mencode(\n\u001b[1;32m     16\u001b[0m     x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     17\u001b[0m     y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m     tooltip\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# show tooltip with x and y values \u001b[39;00m\n\u001b[1;32m     19\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'factorial' is not defined"
     ]
    }
   ],
   "source": [
    "## Claude - FAIL\n",
    "import altair as alt\n",
    "import numpy as np \n",
    "\n",
    "n = 10  # number of trials\n",
    "p = 0.5 # probability of success\n",
    "\n",
    "x = np.arange(n+1)  # x-axis values, 0 to n\n",
    "y = []              # y-axis values (probabilities)\n",
    "\n",
    "# calculate binomial PMF \n",
    "for i in x: \n",
    "    y.append((factorial(n) / (factorial(i) * factorial(n-i))) * (p**i) * ((1-p)**(n-i)))\n",
    "\n",
    "# create Altair chart \n",
    "chart = alt.Chart(pd.DataFrame({'x': x, 'y': y})).mark_bar().encode(\n",
    "    x='x', \n",
    "    y='y',\n",
    "    tooltip=['x', 'y']  # show tooltip with x and y values \n",
    ")\n",
    "\n",
    "# display the chart \n",
    "chart.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b16511f61745458c9cfabb5e692c9287\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b16511f61745458c9cfabb5e692c9287\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b16511f61745458c9cfabb5e692c9287\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-247f43c25aa325850526b6e19b6d2165\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"field\": \"Outcome - k in the formula\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"PMF\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-247f43c25aa325850526b6e19b6d2165\": [{\"Outcome - k in the formula\": 0, \"PMF\": 0.0009765625}, {\"Outcome - k in the formula\": 1, \"PMF\": 0.009765625}, {\"Outcome - k in the formula\": 2, \"PMF\": 0.0439453125}, {\"Outcome - k in the formula\": 3, \"PMF\": 0.1171875}, {\"Outcome - k in the formula\": 4, \"PMF\": 0.205078125}, {\"Outcome - k in the formula\": 5, \"PMF\": 0.24609375}, {\"Outcome - k in the formula\": 6, \"PMF\": 0.205078125}, {\"Outcome - k in the formula\": 7, \"PMF\": 0.1171875}, {\"Outcome - k in the formula\": 8, \"PMF\": 0.0439453125}, {\"Outcome - k in the formula\": 9, \"PMF\": 0.009765625}, {\"Outcome - k in the formula\": 10, \"PMF\": 0.0009765625}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## GPT-4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "n = 10\n",
    "p = 0.5\n",
    "\n",
    "# Generate the possible outcomes (from 0 to n)\n",
    "x = np.arange(n+1)\n",
    "\n",
    "# Calculate the PMF for each outcome\n",
    "pmf = np.array([np.math.comb(n, k) * (p**k) * ((1-p)**(n-k)) for k in x])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Outcome - k in the formula': x,\n",
    "    'PMF': pmf\n",
    "})\n",
    "\n",
    "# Create the Altair chart\n",
    "chart = alt.Chart(df).mark_bar().encode(\n",
    "    x='Outcome - k in the formula:O',\n",
    "    y='PMF:Q'\n",
    ")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-3e9352ca08984bc995afcc10d4f1503c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-3e9352ca08984bc995afcc10d4f1503c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-3e9352ca08984bc995afcc10d4f1503c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-518619eec077c1c64e087e46e26014c0\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"y\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-518619eec077c1c64e087e46e26014c0\": [{\"x\": -5.0, \"y\": 1.0769760042543276e-07}, {\"x\": -4.98998998998999, \"y\": 1.1378745275716772e-07}, {\"x\": -4.97997997997998, \"y\": 1.202096153207879e-07}, {\"x\": -4.96996996996997, \"y\": 1.2698152044385167e-07}, {\"x\": -4.95995995995996, \"y\": 1.3412147532284694e-07}, {\"x\": -4.94994994994995, \"y\": 1.416487037647244e-07}, {\"x\": -4.93993993993994, \"y\": 1.4958338980561166e-07}, {\"x\": -4.92992992992993, \"y\": 1.57946723285299e-07}, {\"x\": -4.91991991991992, \"y\": 1.6676094745909804e-07}, {\"x\": -4.90990990990991, \"y\": 1.7604940873177798e-07}, {\"x\": -4.8998998998999, \"y\": 1.8583660860149615e-07}, {\"x\": -4.88988988988989, \"y\": 1.9614825790495417e-07}, {\"x\": -4.87987987987988, \"y\": 2.0701133345844392e-07}, {\"x\": -4.86986986986987, \"y\": 2.184541371929849e-07}, {\"x\": -4.85985985985986, \"y\": 2.3050635788540945e-07}, {\"x\": -4.84984984984985, \"y\": 2.431991355910328e-07}, {\"x\": -4.83983983983984, \"y\": 2.5656512888743794e-07}, {\"x\": -4.82982982982983, \"y\": 2.706385850429331e-07}, {\"x\": -4.81981981981982, \"y\": 2.8545541322738314e-07}, {\"x\": -4.80980980980981, \"y\": 3.0105326088740924e-07}, {\"x\": -4.7997997997998, \"y\": 3.1747159341236084e-07}, {\"x\": -4.78978978978979, \"y\": 3.3475177722202654e-07}, {\"x\": -4.77977977977978, \"y\": 3.5293716641174036e-07}, {\"x\": -4.76976976976977, \"y\": 3.7207319309539286e-07}, {\"x\": -4.75975975975976, \"y\": 3.922074615918383e-07}, {\"x\": -4.74974974974975, \"y\": 4.1338984660534204e-07}, {\"x\": -4.73973973973974, \"y\": 4.3567259555599743e-07}, {\"x\": -4.72972972972973, \"y\": 4.591104352215143e-07}, {\"x\": -4.71971971971972, \"y\": 4.837606828573891e-07}, {\"x\": -4.70970970970971, \"y\": 5.096833619682631e-07}, {\"x\": -4.6996996996997, \"y\": 5.369413229092166e-07}, {\"x\": -4.68968968968969, \"y\": 5.656003685018914e-07}, {\"x\": -4.67967967967968, \"y\": 5.957293848566347e-07}, {\"x\": -4.66966966966967, \"y\": 6.274004775983332e-07}, {\"x\": -4.65965965965966, \"y\": 6.60689113700295e-07}, {\"x\": -4.64964964964965, \"y\": 6.956742691373823e-07}, {\"x\": -4.63963963963964, \"y\": 7.324385825766583e-07}, {\"x\": -4.62962962962963, \"y\": 7.710685153310395e-07}, {\"x\": -4.61961961961962, \"y\": 8.116545178089131e-07}, {\"x\": -4.60960960960961, \"y\": 8.542912027003071e-07}, {\"x\": -4.5995995995996, \"y\": 8.99077525148068e-07}, {\"x\": -4.58958958958959, \"y\": 9.461169701605436e-07}, {\"x\": -4.57957957957958, \"y\": 9.955177475305708e-07}, {\"x\": -4.56956956956957, \"y\": 1.0473929945340423e-06}, {\"x\": -4.55955955955956, \"y\": 1.1018609866900546e-06}, {\"x\": -4.54954954954955, \"y\": 1.1590453568735517e-06}, {\"x\": -4.53953953953954, \"y\": 1.2190753230805817e-06}, {\"x\": -4.52952952952953, \"y\": 1.2820859251556582e-06}, {\"x\": -4.51951951951952, \"y\": 1.3482182708003236e-06}, {\"x\": -4.50950950950951, \"y\": 1.417619791191953e-06}, {\"x\": -4.4994994994995, \"y\": 1.4904445065518642e-06}, {\"x\": -4.48948948948949, \"y\": 1.5668533020121771e-06}, {\"x\": -4.47947947947948, \"y\": 1.6470142141415267e-06}, {\"x\": -4.46946946946947, \"y\": 1.7311027285004626e-06}, {\"x\": -4.45945945945946, \"y\": 1.81930208860858e-06}, {\"x\": -4.44944944944945, \"y\": 1.9118036167167326e-06}, {\"x\": -4.43943943943944, \"y\": 2.00880704678927e-06}, {\"x\": -4.42942942942943, \"y\": 2.1105208701131734e-06}, {\"x\": -4.41941941941942, \"y\": 2.2171626939630483e-06}, {\"x\": -4.40940940940941, \"y\": 2.328959613763381e-06}, {\"x\": -4.3993993993994, \"y\": 2.446148599202056e-06}, {\"x\": -4.38938938938939, \"y\": 2.568976894762167e-06}, {\"x\": -4.37937937937938, \"y\": 2.6977024351522746e-06}, {\"x\": -4.36936936936937, \"y\": 2.832594276128803e-06}, {\"x\": -4.35935935935936, \"y\": 2.9739330412179487e-06}, {\"x\": -4.34934934934935, \"y\": 3.1220113848585625e-06}, {\"x\": -4.33933933933934, \"y\": 3.2771344725017625e-06}, {\"x\": -4.32932932932933, \"y\": 3.4396204782174817e-06}, {\"x\": -4.31931931931932, \"y\": 3.6098011003732454e-06}, {\"x\": -4.3093093093093096, \"y\": 3.7880220959653382e-06}, {\"x\": -4.2992992992992995, \"y\": 3.974643834198022e-06}, {\"x\": -4.2892892892892895, \"y\": 4.170041869922268e-06}, {\"x\": -4.2792792792792795, \"y\": 4.374607537561128e-06}, {\"x\": -4.2692692692692695, \"y\": 4.588748566165342e-06}, {\"x\": -4.2592592592592595, \"y\": 4.812889716259162e-06}, {\"x\": -4.2492492492492495, \"y\": 5.047473439153067e-06}, {\"x\": -4.2392392392392395, \"y\": 5.292960559417196e-06}, {\"x\": -4.2292292292292295, \"y\": 5.549830981226514e-06}, {\"x\": -4.2192192192192195, \"y\": 5.818584419306336e-06}, {\"x\": -4.2092092092092095, \"y\": 6.099741155224531e-06}, {\"x\": -4.1991991991991995, \"y\": 6.3938428197949236e-06}, {\"x\": -4.1891891891891895, \"y\": 6.701453202374608e-06}, {\"x\": -4.1791791791791795, \"y\": 7.023159087856538e-06}, {\"x\": -4.1691691691691695, \"y\": 7.359571122177367e-06}, {\"x\": -4.1591591591591595, \"y\": 7.711324707179724e-06}, {\"x\": -4.1491491491491495, \"y\": 8.079080925687357e-06}, {\"x\": -4.1391391391391394, \"y\": 8.463527497670691e-06}, {\"x\": -4.129129129129129, \"y\": 8.865379768400677e-06}, {\"x\": -4.119119119119119, \"y\": 9.285381729508028e-06}, {\"x\": -4.109109109109109, \"y\": 9.724307073885275e-06}, {\"x\": -4.099099099099099, \"y\": 1.0182960285389689e-05}, {\"x\": -4.089089089089089, \"y\": 1.0662177764324805e-05}, {\"x\": -4.079079079079079, \"y\": 1.11628289896996e-05}, {\"x\": -4.069069069069069, \"y\": 1.1685817719284789e-05}, {\"x\": -4.059059059059059, \"y\": 1.2232083228506532e-05}, {\"x\": -4.049049049049049, \"y\": 1.2802601589239198e-05}, {\"x\": -4.039039039039039, \"y\": 1.339838698957965e-05}, {\"x\": -4.029029029029029, \"y\": 1.4020493095707062e-05}, {\"x\": -4.019019019019019, \"y\": 1.4670014456953264e-05}, {\"x\": -4.009009009009009, \"y\": 1.5348087955230396e-05}, {\"x\": -3.998998998998999, \"y\": 1.6055894299984016e-05}, {\"x\": -3.988988988988989, \"y\": 1.6794659569860885e-05}, {\"x\": -3.978978978978979, \"y\": 1.756565680230318e-05}, {\"x\": -3.968968968968969, \"y\": 1.83702076323011e-05}, {\"x\": -3.958958958958959, \"y\": 1.920968398155867e-05}, {\"x\": -3.948948948948949, \"y\": 2.008550979934784e-05}, {\"x\": -3.938938938938939, \"y\": 2.0999162856348385e-05}, {\"x\": -3.928928928928929, \"y\": 2.195217659279173e-05}, {\"x\": -3.918918918918919, \"y\": 2.2946142022248434e-05}, {\"x\": -3.908908908908909, \"y\": 2.3982709692420183e-05}, {\"x\": -3.898898898898899, \"y\": 2.506359170431756e-05}, {\"x\": -3.888888888888889, \"y\": 2.6190563791226668e-05}, {\"x\": -3.878878878878879, \"y\": 2.7365467458886663e-05}, {\"x\": -3.868868868868869, \"y\": 2.85902121883227e-05}, {\"x\": -3.858858858858859, \"y\": 2.9866777702796393e-05}, {\"x\": -3.848848848848849, \"y\": 3.1197216300357975e-05}, {\"x\": -3.838838838838839, \"y\": 3.258365525350147e-05}, {\"x\": -3.828828828828829, \"y\": 3.402829927744599e-05}, {\"x\": -3.818818818818819, \"y\": 3.553343306858169e-05}, {\"x\": -3.808808808808809, \"y\": 3.7101423914640406e-05}, {\"x\": -3.798798798798799, \"y\": 3.873472437816567e-05}, {\"x\": -3.7887887887887888, \"y\": 4.043587505487717e-05}, {\"x\": -3.7787787787787788, \"y\": 4.220750740853875e-05}, {\"x\": -3.7687687687687688, \"y\": 4.405234668395614e-05}, {\"x\": -3.7587587587587588, \"y\": 4.597321489974774e-05}, {\"x\": -3.7487487487487487, \"y\": 4.797303392254331e-05}, {\"x\": -3.7387387387387387, \"y\": 5.005482862428265e-05}, {\"x\": -3.7287287287287287, \"y\": 5.2221730124298464e-05}, {\"x\": -3.7187187187187187, \"y\": 5.447697911787911e-05}, {\"x\": -3.7087087087087087, \"y\": 5.682392929302179e-05}, {\"x\": -3.6986986986986987, \"y\": 5.9266050837094196e-05}, {\"x\": -3.6886886886886887, \"y\": 6.18069340351338e-05}, {\"x\": -3.6786786786786787, \"y\": 6.44502929615251e-05}, {\"x\": -3.6686686686686687, \"y\": 6.719996926679866e-05}, {\"x\": -3.6586586586586587, \"y\": 7.005993606130746e-05}, {\"x\": -3.6486486486486487, \"y\": 7.303430189753642e-05}, {\"x\": -3.6386386386386387, \"y\": 7.61273148528121e-05}, {\"x\": -3.6286286286286287, \"y\": 7.934336671417543e-05}, {\"x\": -3.6186186186186187, \"y\": 8.268699726718868e-05}, {\"x\": -3.6086086086086087, \"y\": 8.616289869044367e-05}, {\"x\": -3.5985985985985987, \"y\": 8.977592005754064e-05}, {\"x\": -3.5885885885885886, \"y\": 9.353107194830305e-05}, {\"x\": -3.5785785785785786, \"y\": 9.743353117098991e-05}, {\"x\": -3.5685685685685686, \"y\": 0.00010148864559726312}, {\"x\": -3.5585585585585586, \"y\": 0.00010570193911165725}, {\"x\": -3.5485485485485486, \"y\": 0.00011007911667729332}, {\"x\": -3.5385385385385386, \"y\": 0.00011462606951956675}, {\"x\": -3.5285285285285286, \"y\": 0.0001193488804295245}, {\"x\": -3.5185185185185186, \"y\": 0.00012425382918863586}, {\"x\": -3.5085085085085086, \"y\": 0.000129347398116642}, {\"x\": -3.4984984984984986, \"y\": 0.00013463627774415338}, {\"x\": -3.4884884884884886, \"y\": 0.0001401273726116377}, {\"x\": -3.4784784784784786, \"y\": 0.0001458278071964298}, {\"x\": -3.4684684684684686, \"y\": 0.00015174493196935473}, {\"x\": -3.4584584584584586, \"y\": 0.0001578863295825402}, {\"x\": -3.4484484484484486, \"y\": 0.0001642598211899589}, {\"x\": -3.4384384384384385, \"y\": 0.00017087347290220922}, {\"x\": -3.4284284284284285, \"y\": 0.00017773560237701013}, {\"x\": -3.4184184184184185, \"y\": 0.00018485478554684635}, {\"x\": -3.4084084084084085, \"y\": 0.00019223986348515968}, {\"x\": -3.3983983983983985, \"y\": 0.00019989994941244237}, {\"x\": -3.388388388388388, \"y\": 0.0002078444358435395}, {\"x\": -3.378378378378378, \"y\": 0.0002160830018774177}, {\"x\": -3.368368368368368, \"y\": 0.0002246256206306134}, {\"x\": -3.358358358358358, \"y\": 0.00023348256681550607}, {\"x\": -3.348348348348348, \"y\": 0.00024266442446451867}, {\"x\": -3.338338338338338, \"y\": 0.00025218209480127506}, {\"x\": -3.328328328328328, \"y\": 0.00026204680425968526}, {\"x\": -3.318318318318318, \"y\": 0.00027227011265186274}, {\"x\": -3.308308308308308, \"y\": 0.0002828639214857023}, {\"x\": -3.298298298298298, \"y\": 0.00029384048243287774}, {\"x\": -3.288288288288288, \"y\": 0.0003052124059479366}, {\"x\": -3.278278278278278, \"y\": 0.0003169926700390912}, {\"x\": -3.268268268268268, \"y\": 0.00032919462919121567}, {\"x\": -3.258258258258258, \"y\": 0.00034183202344147524}, {\"x\": -3.248248248248248, \"y\": 0.00035491898760791463}, {\"x\": -3.238238238238238, \"y\": 0.0003684700606712437}, {\"x\": -3.228228228228228, \"y\": 0.00038250019530994896}, {\"x\": -3.218218218218218, \"y\": 0.0003970247675887641}, {\"x\": -3.208208208208208, \"y\": 0.00041205958680041804}, {\"x\": -3.198198198198198, \"y\": 0.00042762090546046694}, {\"x\": -3.188188188188188, \"y\": 0.00044372542945490416}, {\"x\": -3.178178178178178, \"y\": 0.00046039032834011733}, {\"x\": -3.168168168168168, \"y\": 0.00047763324579463734}, {\"x\": -3.158158158158158, \"y\": 0.0004954723102219934}, {\"x\": -3.148148148148148, \"y\": 0.0005139261455038617}, {\"x\": -3.138138138138138, \"y\": 0.0005330138819025444}, {\"x\": -3.128128128128128, \"y\": 0.0005527551671116879}, {\"x\": -3.118118118118118, \"y\": 0.0005731701774539887}, {\"x\": -3.108108108108108, \"y\": 0.0005942796292244939}, {\"x\": -3.098098098098098, \"y\": 0.0006161047901779482}, {\"x\": -3.088088088088088, \"y\": 0.0006386674911584605}, {\"x\": -3.078078078078078, \"y\": 0.000661990137869634}, {\"x\": -3.068068068068068, \"y\": 0.000686095722783092}, {\"x\": -3.058058058058058, \"y\": 0.000711007837183193}, {\"x\": -3.048048048048048, \"y\": 0.0007367506833455316}, {\"x\": -3.038038038038038, \"y\": 0.0007633490868466401}, {\"x\": -3.028028028028028, \"y\": 0.0007908285090021272}, {\"x\": -3.018018018018018, \"y\": 0.0008192150594302883}, {\"x\": -3.008008008008008, \"y\": 0.0008485355087380276}, {\"x\": -2.997997997997998, \"y\": 0.0008788173013257357}, {\"x\": -2.987987987987988, \"y\": 0.0009100885683075585}, {\"x\": -2.977977977977978, \"y\": 0.0009423781405432786}, {\"x\": -2.967967967967968, \"y\": 0.0009757155617778175}, {\"x\": -2.957957957957958, \"y\": 0.0010101311018841585}, {\"x\": -2.947947947947948, \"y\": 0.0010456557702052483}, {\"x\": -2.937937937937938, \"y\": 0.0010823213289902203}, {\"x\": -2.9279279279279278, \"y\": 0.001120160306920058}, {\"x\": -2.9179179179179178, \"y\": 0.0011592060127175445}, {\"x\": -2.9079079079079078, \"y\": 0.0011994925488361696}, {\"x\": -2.8978978978978978, \"y\": 0.0012410548252223333}, {\"x\": -2.8878878878878878, \"y\": 0.0012839285731450383}, {\"x\": -2.8778778778778777, \"y\": 0.001328150359086905}, {\"x\": -2.8678678678678677, \"y\": 0.001373757598690193}, {\"x\": -2.8578578578578577, \"y\": 0.001420788570751154}, {\"x\": -2.8478478478478477, \"y\": 0.0014692824312558547}, {\"x\": -2.8378378378378377, \"y\": 0.0015192792274503057}, {\"x\": -2.8278278278278277, \"y\": 0.0015708199119374609}, {\"x\": -2.8178178178178177, \"y\": 0.0016239463567933935}, {\"x\": -2.8078078078078077, \"y\": 0.0016787013676946674}, {\"x\": -2.7977977977977977, \"y\": 0.0017351286980486563}, {\"x\": -2.7877877877877877, \"y\": 0.0017932730631182658}, {\"x\": -2.7777777777777777, \"y\": 0.001853180154132231}, {\"x\": -2.7677677677677677, \"y\": 0.0019148966523718934}, {\"x\": -2.7577577577577577, \"y\": 0.0019784702432250646}, {\"x\": -2.7477477477477477, \"y\": 0.0020439496301972535}, {\"x\": -2.7377377377377377, \"y\": 0.0021113845488703238}, {\"x\": -2.7277277277277276, \"y\": 0.0021808257807982736}, {\"x\": -2.7177177177177176, \"y\": 0.0022523251673295715}, {\"x\": -2.7077077077077076, \"y\": 0.0023259356233451896}, {\"x\": -2.6976976976976976, \"y\": 0.002401711150901168}, {\"x\": -2.6876876876876876, \"y\": 0.0024797068527642138}, {\"x\": -2.6776776776776776, \"y\": 0.002559978945828642}, {\"x\": -2.6676676676676676, \"y\": 0.002642584774402506}, {\"x\": -2.6576576576576576, \"y\": 0.002727582823350621}, {\"x\": -2.6476476476476476, \"y\": 0.0028150327310818043}, {\"x\": -2.6376376376376376, \"y\": 0.002904995302367349}, {\"x\": -2.6276276276276276, \"y\": 0.002997532520977508}, {\"x\": -2.6176176176176176, \"y\": 0.0030927075621224173}, {\"x\": -2.6076076076076076, \"y\": 0.0031905848046836047}, {\"x\": -2.5975975975975976, \"y\": 0.003291229843221977}, {\"x\": -2.5875875875875876, \"y\": 0.0033947094997478096}, {\"x\": -2.5775775775775776, \"y\": 0.003501091835238055}, {\"x\": -2.5675675675675675, \"y\": 0.003610446160885971}, {\"x\": -2.5575575575575575, \"y\": 0.0037228430490677516}, {\"x\": -2.5475475475475475, \"y\": 0.0038383543440106234}, {\"x\": -2.5375375375375375, \"y\": 0.003957053172146569}, {\"x\": -2.5275275275275275, \"y\": 0.004079013952135558}, {\"x\": -2.5175175175175175, \"y\": 0.004204312404541935}, {\"x\": -2.5075075075075075, \"y\": 0.004333025561147297}, {\"x\": -2.4974974974974975, \"y\": 0.004465231773883021}, {\"x\": -2.4874874874874875, \"y\": 0.0046010107233652705}, {\"x\": -2.4774774774774775, \"y\": 0.004740443427015105}, {\"x\": -2.4674674674674675, \"y\": 0.00488361224674609}, {\"x\": -2.4574574574574575, \"y\": 0.005030600896201588}, {\"x\": -2.4474474474474475, \"y\": 0.005181494447523601}, {\"x\": -2.4374374374374375, \"y\": 0.005336379337634964}, {\"x\": -2.4274274274274275, \"y\": 0.005495343374016366}, {\"x\": -2.4174174174174174, \"y\": 0.005658475739959513}, {\"x\": -2.4074074074074074, \"y\": 0.005825866999277619}, {\"x\": -2.3973973973973974, \"y\": 0.005997609100454129}, {\"x\": -2.3873873873873874, \"y\": 0.0061737953802104934}, {\"x\": -2.3773773773773774, \"y\": 0.006354520566473691}, {\"x\": -2.3673673673673674, \"y\": 0.006539880780723825}, {\"x\": -2.3573573573573574, \"y\": 0.006729973539702385}, {\"x\": -2.3473473473473474, \"y\": 0.0069248977564612315}, {\"x\": -2.3373373373373374, \"y\": 0.007124753740732494}, {\"x\": -2.3273273273273274, \"y\": 0.007329643198599466}, {\"x\": -2.3173173173173174, \"y\": 0.007539669231448381}, {\"x\": -2.3073073073073074, \"y\": 0.007754936334180997}, {\"x\": -2.2972972972972974, \"y\": 0.007975550392667796}, {\"x\": -2.2872872872872874, \"y\": 0.00820161868042165}, {\"x\": -2.2772772772772774, \"y\": 0.008433249854471645}, {\"x\": -2.2672672672672673, \"y\": 0.00867055395041687}, {\"x\": -2.2572572572572573, \"y\": 0.008913642376639972}, {\"x\": -2.2472472472472473, \"y\": 0.009162627907660202}, {\"x\": -2.2372372372372373, \"y\": 0.009417624676605863}, {\"x\": -2.2272272272272273, \"y\": 0.009678748166786008}, {\"x\": -2.2172172172172173, \"y\": 0.009946115202341399}, {\"x\": -2.2072072072072073, \"y\": 0.010219843937954798}, {\"x\": -2.1971971971971973, \"y\": 0.010500053847600747}, {\"x\": -2.1871871871871873, \"y\": 0.010786865712315203}, {\"x\": -2.1771771771771773, \"y\": 0.01108040160696552}, {\"x\": -2.1671671671671673, \"y\": 0.01138078488600132}, {\"x\": -2.1571571571571573, \"y\": 0.011688140168167278}, {\"x\": -2.1471471471471473, \"y\": 0.012002593320158744}, {\"x\": -2.1371371371371373, \"y\": 0.012324271439201544}, {\"x\": -2.1271271271271273, \"y\": 0.012653302834537538}, {\"x\": -2.1171171171171173, \"y\": 0.012989817007797779}, {\"x\": -2.1071071071071072, \"y\": 0.013333944632245385}, {\"x\": -2.0970970970970972, \"y\": 0.013685817530870602}, {\"x\": -2.0870870870870872, \"y\": 0.01404556865332092}, {\"x\": -2.0770770770770772, \"y\": 0.014413332051649354}, {\"x\": -2.067067067067067, \"y\": 0.014789242854864559}, {\"x\": -2.057057057057057, \"y\": 0.015173437242266706}, {\"x\": -2.047047047047047, \"y\": 0.015566052415553625}, {\"x\": -2.037037037037037, \"y\": 0.015967226569682084}, {\"x\": -2.027027027027027, \"y\": 0.016377098862469696}, {\"x\": -2.017017017017017, \"y\": 0.016795809382923195}, {\"x\": -2.007007007007007, \"y\": 0.01722349911827979}, {\"x\": -1.9969969969969972, \"y\": 0.017660309919748388}, {\"x\": -1.9869869869869872, \"y\": 0.018106384466938553}, {\"x\": -1.9769769769769772, \"y\": 0.018561866230965108}, {\"x\": -1.9669669669669672, \"y\": 0.019026899436217683}, {\"x\": -1.9569569569569571, \"y\": 0.019501629020784294}, {\"x\": -1.9469469469469471, \"y\": 0.019986200595519615}, {\"x\": -1.9369369369369371, \"y\": 0.020480760401748593}, {\"x\": -1.9269269269269271, \"y\": 0.02098545526759721}, {\"x\": -1.9169169169169171, \"y\": 0.021500432562942925}, {\"x\": -1.9069069069069071, \"y\": 0.022025840152977958}, {\"x\": -1.8968968968968971, \"y\": 0.022561826350379493}, {\"x\": -1.886886886886887, \"y\": 0.023108539866081808}, {\"x\": -1.876876876876877, \"y\": 0.02366612975864603}, {\"x\": -1.866866866866867, \"y\": 0.024234745382224226}, {\"x\": -1.856856856856857, \"y\": 0.024814536333115485}, {\"x\": -1.846846846846847, \"y\": 0.025405652394912392}, {\"x\": -1.836836836836837, \"y\": 0.02600824348223757}, {\"x\": -1.826826826826827, \"y\": 0.02662245958307065}, {\"x\": -1.816816816816817, \"y\": 0.027248450699667234}, {\"x\": -1.806806806806807, \"y\": 0.02788636678807242}, {\"x\": -1.796796796796797, \"y\": 0.02853635769623232}, {\"x\": -1.7867867867867866, \"y\": 0.029198573100708634}, {\"x\": -1.7767767767767766, \"y\": 0.029873162442001402}, {\"x\": -1.7667667667667666, \"y\": 0.030560274858487675}, {\"x\": -1.7567567567567566, \"y\": 0.03126005911898342}, {\"x\": -1.7467467467467466, \"y\": 0.03197266355393825}, {\"x\": -1.7367367367367366, \"y\": 0.032698235985273175}, {\"x\": -1.7267267267267266, \"y\": 0.033436923654873246}, {\"x\": -1.7167167167167166, \"y\": 0.03418887315174756}, {\"x\": -1.7067067067067065, \"y\": 0.034954230337870804}, {\"x\": -1.6966966966966965, \"y\": 0.035733140272721786}, {\"x\": -1.6866866866866865, \"y\": 0.03652574713653528}, {\"x\": -1.6766766766766765, \"y\": 0.037332194152285156}, {\"x\": -1.6666666666666665, \"y\": 0.03815262350641798}, {\"x\": -1.6566566566566565, \"y\": 0.038987176268357446}, {\"x\": -1.6466466466466465, \"y\": 0.03983599230880148}, {\"x\": -1.6366366366366365, \"y\": 0.04069921021683517}, {\"x\": -1.6266266266266265, \"y\": 0.041576967215883893}, {\"x\": -1.6166166166166165, \"y\": 0.04246939907853251}, {\"x\": -1.6066066066066065, \"y\": 0.04337664004023798}, {\"x\": -1.5965965965965965, \"y\": 0.04429882271196352}, {\"x\": -1.5865865865865865, \"y\": 0.04523607799176482}, {\"x\": -1.5765765765765765, \"y\": 0.046188534975359116}, {\"x\": -1.5665665665665665, \"y\": 0.04715632086571024}, {\"x\": -1.5565565565565564, \"y\": 0.04813956088166341}, {\"x\": -1.5465465465465464, \"y\": 0.04913837816566554}, {\"x\": -1.5365365365365364, \"y\": 0.0501528936906078}, {\"x\": -1.5265265265265264, \"y\": 0.05118322616582868}, {\"x\": -1.5165165165165164, \"y\": 0.05222949194231741}, {\"x\": -1.5065065065065064, \"y\": 0.05329180491715854}, {\"x\": -1.4964964964964964, \"y\": 0.05437027643726041}, {\"x\": -1.4864864864864864, \"y\": 0.05546501520241107}, {\"x\": -1.4764764764764764, \"y\": 0.05657612716770705}, {\"x\": -1.4664664664664664, \"y\": 0.05770371544540137}, {\"x\": -1.4564564564564564, \"y\": 0.058847880206218776}, {\"x\": -1.4464464464464464, \"y\": 0.060008718580187505}, {\"x\": -1.4364364364364364, \"y\": 0.0611863245570379}, {\"x\": -1.4264264264264264, \"y\": 0.06238078888622016}, {\"x\": -1.4164164164164164, \"y\": 0.063592198976594}, {\"x\": -1.4064064064064064, \"y\": 0.06482063879584493}, {\"x\": -1.3963963963963963, \"y\": 0.06606618876968272}, {\"x\": -1.3863863863863863, \"y\": 0.06732892568087911}, {\"x\": -1.3763763763763763, \"y\": 0.06860892256820297}, {\"x\": -1.3663663663663663, \"y\": 0.0699062486253121}, {\"x\": -1.3563563563563563, \"y\": 0.07122096909966222}, {\"x\": -1.3463463463463463, \"y\": 0.07255314519149518}, {\"x\": -1.3363363363363363, \"y\": 0.0739028339529686}, {\"x\": -1.3263263263263263, \"y\": 0.07527008818749135}, {\"x\": -1.3163163163163163, \"y\": 0.0766549563493294}, {\"x\": -1.3063063063063063, \"y\": 0.07805748244354818}, {\"x\": -1.2962962962962963, \"y\": 0.0794777059263584}, {\"x\": -1.2862862862862863, \"y\": 0.08091566160593304}, {\"x\": -1.2762762762762763, \"y\": 0.0823713795437645}, {\"x\": -1.2662662662662663, \"y\": 0.08384488495663138}, {\"x\": -1.2562562562562563, \"y\": 0.08533619811924552}, {\"x\": -1.2462462462462462, \"y\": 0.0868453342676506}, {\"x\": -1.2362362362362362, \"y\": 0.0883723035034442}, {\"x\": -1.2262262262262262, \"y\": 0.08991711069889602}, {\"x\": -1.2162162162162162, \"y\": 0.09147975540303604}, {\"x\": -1.2062062062062062, \"y\": 0.09306023174878604}, {\"x\": -1.1961961961961962, \"y\": 0.09465852836120948}, {\"x\": -1.1861861861861862, \"y\": 0.09627462826695465}, {\"x\": -1.1761761761761762, \"y\": 0.09790850880496653}, {\"x\": -1.1661661661661662, \"y\": 0.09956014153854345}, {\"x\": -1.1561561561561562, \"y\": 0.10122949216881467}, {\"x\": -1.1461461461461462, \"y\": 0.10291652044971562}, {\"x\": -1.1361361361361362, \"y\": 0.10462118010453723}, {\"x\": -1.1261261261261262, \"y\": 0.10634341874412712}, {\"x\": -1.1161161161161162, \"y\": 0.10808317778681854}, {\"x\": -1.1061061061061062, \"y\": 0.10984039238016555}, {\"x\": -1.0960960960960962, \"y\": 0.11161499132456047}, {\"x\": -1.0860860860860861, \"y\": 0.11340689699881154}, {\"x\": -1.0760760760760761, \"y\": 0.11521602528775708}, {\"x\": -1.0660660660660661, \"y\": 0.11704228551199346}, {\"x\": -1.0560560560560561, \"y\": 0.11888558035979292}, {\"x\": -1.0460460460460461, \"y\": 0.12074580582128802}, {\"x\": -1.0360360360360361, \"y\": 0.12262285112499778}, {\"x\": -1.026026026026026, \"y\": 0.12451659867677141}, {\"x\": -1.016016016016016, \"y\": 0.1264269240012243}, {\"x\": -1.006006006006006, \"y\": 0.12835369568574037}, {\"x\": -0.9959959959959956, \"y\": 0.1302967753271146}, {\"x\": -0.9859859859859856, \"y\": 0.13225601748090776}, {\"x\": -0.9759759759759756, \"y\": 0.13423126961358706}, {\"x\": -0.9659659659659656, \"y\": 0.13622237205752188}, {\"x\": -0.9559559559559556, \"y\": 0.1382291579689059}, {\"x\": -0.9459459459459456, \"y\": 0.14025145328867464}, {\"x\": -0.9359359359359356, \"y\": 0.14228907670648677}, {\"x\": -0.9259259259259256, \"y\": 0.14434183962783523}, {\"x\": -0.9159159159159156, \"y\": 0.14640954614435478}, {\"x\": -0.9059059059059056, \"y\": 0.14849199300739024}, {\"x\": -0.8958958958958956, \"y\": 0.15058896960488793}, {\"x\": -0.8858858858858856, \"y\": 0.15270025794167244}, {\"x\": -0.8758758758758756, \"y\": 0.15482563262316867}, {\"x\": -0.8658658658658656, \"y\": 0.1569648608426277}, {\"x\": -0.8558558558558556, \"y\": 0.15911770237191286}, {\"x\": -0.8458458458458455, \"y\": 0.16128390955590213}, {\"x\": -0.8358358358358355, \"y\": 0.16346322731055907}, {\"x\": -0.8258258258258255, \"y\": 0.16565539312472474}, {\"x\": -0.8158158158158155, \"y\": 0.16786013706567948}, {\"x\": -0.8058058058058055, \"y\": 0.17007718178852255}, {\"x\": -0.7957957957957955, \"y\": 0.17230624254941476}, {\"x\": -0.7857857857857855, \"y\": 0.17454702722272822}, {\"x\": -0.7757757757757755, \"y\": 0.1767992363221433}, {\"x\": -0.7657657657657655, \"y\": 0.17906256302573298}, {\"x\": -0.7557557557557555, \"y\": 0.18133669320507023}, {\"x\": -0.7457457457457455, \"y\": 0.1836213054583935}, {\"x\": -0.7357357357357355, \"y\": 0.18591607114786177}, {\"x\": -0.7257257257257255, \"y\": 0.18822065444092856}, {\"x\": -0.7157157157157155, \"y\": 0.19053471235586203}, {\"x\": -0.7057057057057055, \"y\": 0.1928578948114353}, {\"x\": -0.6956956956956954, \"y\": 0.1951898446808084}, {\"x\": -0.6856856856856854, \"y\": 0.19753019784962125}, {\"x\": -0.6756756756756754, \"y\": 0.19987858327831354}, {\"x\": -0.6656656656656654, \"y\": 0.20223462306868498}, {\"x\": -0.6556556556556554, \"y\": 0.20459793253470646}, {\"x\": -0.6456456456456454, \"y\": 0.2069681202775904}, {\"x\": -0.6356356356356354, \"y\": 0.20934478826512393}, {\"x\": -0.6256256256256254, \"y\": 0.21172753191526802}, {\"x\": -0.6156156156156154, \"y\": 0.2141159401840205}, {\"x\": -0.6056056056056054, \"y\": 0.21650959565753933}, {\"x\": -0.5955955955955954, \"y\": 0.21890807464851877}, {\"x\": -0.5855855855855854, \"y\": 0.221310947296808}, {\"x\": -0.5755755755755754, \"y\": 0.22371777767425904}, {\"x\": -0.5655655655655654, \"y\": 0.22612812389378725}, {\"x\": -0.5555555555555554, \"y\": 0.22854153822262505}, {\"x\": -0.5455455455455454, \"y\": 0.23095756719974525}, {\"x\": -0.5355355355355353, \"y\": 0.2333757517574292}, {\"x\": -0.5255255255255253, \"y\": 0.23579562734694912}, {\"x\": -0.5155155155155153, \"y\": 0.23821672406833314}, {\"x\": -0.5055055055055053, \"y\": 0.24063856680417717}, {\"x\": -0.4954954954954953, \"y\": 0.2430606753574643}, {\"x\": -0.4854854854854853, \"y\": 0.2454825645933502}, {\"x\": -0.4754754754754753, \"y\": 0.24790374458486847}, {\"x\": -0.4654654654654653, \"y\": 0.2503237207625083}, {\"x\": -0.4554554554554553, \"y\": 0.2527419940676118}, {\"x\": -0.4454454454454453, \"y\": 0.25515806110953615}, {\"x\": -0.4354354354354353, \"y\": 0.2575714143265233}, {\"x\": -0.4254254254254253, \"y\": 0.2599815421502141}, {\"x\": -0.41541541541541527, \"y\": 0.26238792917374404}, {\"x\": -0.40540540540540526, \"y\": 0.26479005632335245}, {\"x\": -0.39539539539539525, \"y\": 0.2671874010334335}, {\"x\": -0.38538538538538525, \"y\": 0.26957943742495644}, {\"x\": -0.37537537537537524, \"y\": 0.27196563648717714}, {\"x\": -0.36536536536536524, \"y\": 0.274345466262562}, {\"x\": -0.35535535535535523, \"y\": 0.27671839203484033}, {\"x\": -0.3453453453453452, \"y\": 0.27908387652009986}, {\"x\": -0.3353353353353352, \"y\": 0.2814413800608366}, {\"x\": -0.3253253253253252, \"y\": 0.28379036082286757}, {\"x\": -0.3153153153153152, \"y\": 0.28613027499501165}, {\"x\": -0.3053053053053052, \"y\": 0.2884605769914415}, {\"x\": -0.2952952952952952, \"y\": 0.29078071965660723}, {\"x\": -0.2852852852852852, \"y\": 0.29309015447262793}, {\"x\": -0.2752752752752752, \"y\": 0.2953883317690481}, {\"x\": -0.26526526526526517, \"y\": 0.2976747009348494}, {\"x\": -0.25525525525525516, \"y\": 0.2999487106326087}, {\"x\": -0.24524524524524516, \"y\": 0.3022098090146898}, {\"x\": -0.23523523523523515, \"y\": 0.3044574439413545}, {\"x\": -0.22522522522522515, \"y\": 0.30669106320067474}, {\"x\": -0.21521521521521514, \"y\": 0.30891011473012886}, {\"x\": -0.20520520520520513, \"y\": 0.3111140468397584}, {\"x\": -0.19519519519519513, \"y\": 0.3133023084367645}, {\"x\": -0.18518518518518512, \"y\": 0.3154743492514166}, {\"x\": -0.1751751751751751, \"y\": 0.3176296200641487}, {\"x\": -0.1651651651651651, \"y\": 0.31976757293371283}, {\"x\": -0.1551551551551551, \"y\": 0.32188766142626024}, {\"x\": -0.1451451451451451, \"y\": 0.3239893408452186}, {\"x\": -0.1351351351351351, \"y\": 0.32607206846183107}, {\"x\": -0.12512512512512508, \"y\": 0.32813530374622385}, {\"x\": -0.11511511511511507, \"y\": 0.33017850859886483}, {\"x\": -0.10510510510510507, \"y\": 0.33220114758227776}, {\"x\": -0.09509509509509506, \"y\": 0.3342026881528727}, {\"x\": -0.08508508508508505, \"y\": 0.3361826008927541}, {\"x\": -0.07507507507507505, \"y\": 0.33814035974136664}, {\"x\": -0.06506506506506504, \"y\": 0.34007544222683833}, {\"x\": -0.055055055055055035, \"y\": 0.3419873296968791}, {\"x\": -0.04504504504504503, \"y\": 0.34387550754909346}, {\"x\": -0.03503503503503502, \"y\": 0.34573946546056483}, {\"x\": -0.025025025025025016, \"y\": 0.34757869761656957}, {\"x\": -0.01501501501501501, \"y\": 0.3493927029382773}, {\"x\": -0.005005005005005003, \"y\": 0.35118098530929515}, {\"x\": 0.005005005005005003, \"y\": 0.3529430538009131}, {\"x\": 0.01501501501501501, \"y\": 0.3546784228959084}, {\"x\": 0.025025025025025016, \"y\": 0.3563866127107657}, {\"x\": 0.03503503503503502, \"y\": 0.3580671492161724}, {\"x\": 0.04504504504504503, \"y\": 0.35971956445564646}, {\"x\": 0.055055055055055035, \"y\": 0.3613433967621576}, {\"x\": 0.06506506506506504, \"y\": 0.36293819097259994}, {\"x\": 0.07507507507507505, \"y\": 0.36450349863997855}, {\"x\": 0.08508508508508505, \"y\": 0.36603887824317094}, {\"x\": 0.09509509509509506, \"y\": 0.3675438953941269}, {\"x\": 0.10510510510510507, \"y\": 0.36901812304236997}, {\"x\": 0.11511511511511507, \"y\": 0.37046114167666727}, {\"x\": 0.12512512512512508, \"y\": 0.3718725395237332}, {\"x\": 0.1351351351351351, \"y\": 0.3732519127438366}, {\"x\": 0.1451451451451451, \"y\": 0.3745988656231807}, {\"x\": 0.1551551551551551, \"y\": 0.37591301076292766}, {\"x\": 0.1651651651651651, \"y\": 0.3771939692647423}, {\"x\": 0.1751751751751751, \"y\": 0.3784413709127294}, {\"x\": 0.18518518518518512, \"y\": 0.3796548543516437}, {\"x\": 0.19519519519519513, \"y\": 0.3808340672612515}, {\"x\": 0.20520520520520513, \"y\": 0.38197866652672674}, {\"x\": 0.21521521521521514, \"y\": 0.3830883184049661}, {\"x\": 0.22522522522522515, \"y\": 0.3841626986867102}, {\"x\": 0.23523523523523515, \"y\": 0.38520149285436134}, {\"x\": 0.24524524524524516, \"y\": 0.3862043962353887}, {\"x\": 0.25525525525525516, \"y\": 0.3871711141512184}, {\"x\": 0.26526526526526517, \"y\": 0.3881013620615047}, {\"x\": 0.2752752752752752, \"y\": 0.388994865703685}, {\"x\": 0.2852852852852852, \"y\": 0.3898513612277213}, {\"x\": 0.2952952952952952, \"y\": 0.3906705953259368}, {\"x\": 0.3053053053053052, \"y\": 0.391452325357858}, {\"x\": 0.3153153153153152, \"y\": 0.39219631946997474}, {\"x\": 0.3253253253253252, \"y\": 0.3929023567103379}, {\"x\": 0.3353353353353352, \"y\": 0.393570227137913}, {\"x\": 0.3453453453453452, \"y\": 0.39419973192661595}, {\"x\": 0.35535535535535523, \"y\": 0.3947906834639572}, {\"x\": 0.36536536536536524, \"y\": 0.3953429054442267}, {\"x\": 0.37537537537537524, \"y\": 0.39585623295615496}, {\"x\": 0.38538538538538525, \"y\": 0.39633051256498864}, {\"x\": 0.39539539539539525, \"y\": 0.3967656023889232}, {\"x\": 0.40540540540540526, \"y\": 0.397161372169841}, {\"x\": 0.41541541541541527, \"y\": 0.39751770333830316}, {\"x\": 0.4254254254254253, \"y\": 0.3978344890727516}, {\"x\": 0.4354354354354353, \"y\": 0.398111634352879}, {\"x\": 0.4454454454454453, \"y\": 0.39834905600712944}, {\"x\": 0.4554554554554553, \"y\": 0.3985466827542971}, {\"x\": 0.4654654654654653, \"y\": 0.3987044552391927}, {\"x\": 0.4754754754754753, \"y\": 0.3988223260623536}, {\"x\": 0.4854854854854853, \"y\": 0.39890025980377725}, {\"x\": 0.4954954954954953, \"y\": 0.39893823304065923}, {\"x\": 0.5055055055055053, \"y\": 0.39893623435912634}, {\"x\": 0.5155155155155153, \"y\": 0.3988942643599539}, {\"x\": 0.5255255255255253, \"y\": 0.3988123356582649}, {\"x\": 0.5355355355355353, \"y\": 0.3986904728772105}, {\"x\": 0.5455455455455454, \"y\": 0.3985287126356367}, {\"x\": 0.5555555555555554, \"y\": 0.39832710352974543}, {\"x\": 0.5655655655655654, \"y\": 0.39808570610876315}, {\"x\": 0.5755755755755754, \"y\": 0.39780459284463376}, {\"x\": 0.5855855855855854, \"y\": 0.3974838480957578}, {\"x\": 0.5955955955955954, \"y\": 0.3971235680648024}, {\"x\": 0.6056056056056054, \"y\": 0.39672386075061183}, {\"x\": 0.6156156156156154, \"y\": 0.39628484589425284}, {\"x\": 0.6256256256256254, \"y\": 0.39580665491923167}, {\"x\": 0.6356356356356354, \"y\": 0.3952894308659251}, {\"x\": 0.6456456456456454, \"y\": 0.3947333283202713}, {\"x\": 0.6556556556556554, \"y\": 0.3941385133367698}, {\"x\": 0.6656656656656654, \"y\": 0.39350516335584484}, {\"x\": 0.6756756756756754, \"y\": 0.3928334671156295}, {\"x\": 0.6856856856856854, \"y\": 0.39212362455823135}, {\"x\": 0.6956956956956954, \"y\": 0.39137584673054626}, {\"x\": 0.7057057057057055, \"y\": 0.3905903556796875}, {\"x\": 0.7157157157157155, \"y\": 0.3897673843431042}, {\"x\": 0.7257257257257255, \"y\": 0.3889071764334641}, {\"x\": 0.7357357357357355, \"y\": 0.38800998631838096}, {\"x\": 0.7457457457457455, \"y\": 0.38707607889506956}, {\"x\": 0.7557557557557555, \"y\": 0.3861057294600143}, {\"x\": 0.7657657657657655, \"y\": 0.3850992235737424}, {\"x\": 0.7757757757757755, \"y\": 0.38405685692079256}, {\"x\": 0.7857857857857855, \"y\": 0.3829789351649775}, {\"x\": 0.7957957957957955, \"y\": 0.3818657738000383}, {\"x\": 0.8058058058058055, \"y\": 0.3807176979957921}, {\"x\": 0.8158158158158155, \"y\": 0.3795350424398802}, {\"x\": 0.8258258258258255, \"y\": 0.37831815117522166}, {\"x\": 0.8358358358358355, \"y\": 0.3770673774332856}, {\"x\": 0.8458458458458455, \"y\": 0.37578308346329303}, {\"x\": 0.8558558558558556, \"y\": 0.374465640357465}, {\"x\": 0.8658658658658656, \"y\": 0.37311542787243457}, {\"x\": 0.8758758758758756, \"y\": 0.37173283424694337}, {\"x\": 0.8858858858858856, \"y\": 0.3703182560159442}, {\"x\": 0.8958958958958956, \"y\": 0.36887209782123487}, {\"x\": 0.9059059059059056, \"y\": 0.36739477221875017}, {\"x\": 0.9159159159159156, \"y\": 0.3658866994826391}, {\"x\": 0.9259259259259256, \"y\": 0.3643483074062582}, {\"x\": 0.9359359359359356, \"y\": 0.36278003110021323}, {\"x\": 0.9459459459459456, \"y\": 0.3611823127875812}, {\"x\": 0.9559559559559556, \"y\": 0.3595556015964485}, {\"x\": 0.9659659659659656, \"y\": 0.35790035334990056}, {\"x\": 0.9759759759759756, \"y\": 0.3562170303536009}, {\"x\": 0.9859859859859856, \"y\": 0.35450610118109654}, {\"x\": 0.9959959959959956, \"y\": 0.35276804045699056}, {\"x\": 1.0060060060060056, \"y\": 0.35100332863812095}, {\"x\": 1.0160160160160157, \"y\": 0.34921245179288635}, {\"x\": 1.0260260260260257, \"y\": 0.34739590137886117}, {\"x\": 1.0360360360360357, \"y\": 0.34555417401884053}, {\"x\": 1.0460460460460457, \"y\": 0.343687771275459}, {\"x\": 1.0560560560560557, \"y\": 0.3417971994245238}, {\"x\": 1.0660660660660657, \"y\": 0.33988296922720684}, {\"x\": 1.0760760760760757, \"y\": 0.33794559570123767}, {\"x\": 1.0860860860860857, \"y\": 0.33598559789123933}, {\"x\": 1.0960960960960957, \"y\": 0.3340034986383511}, {\"x\": 1.1061061061061057, \"y\": 0.3319998243492789}, {\"x\": 1.1161161161161157, \"y\": 0.3299751047649153}, {\"x\": 1.1261261261261257, \"y\": 0.327929872728672}, {\"x\": 1.1361361361361357, \"y\": 0.3258646639546623}, {\"x\": 1.1461461461461457, \"y\": 0.3237800167958763}, {\"x\": 1.1561561561561557, \"y\": 0.3216764720124866}, {\"x\": 1.1661661661661658, \"y\": 0.3195545725404218}, {\"x\": 1.1761761761761758, \"y\": 0.31741486326034635}, {\"x\": 1.1861861861861858, \"y\": 0.31525789076718125}, {\"x\": 1.1961961961961958, \"y\": 0.31308420314030067}, {\"x\": 1.2062062062062058, \"y\": 0.3108943497145376}, {\"x\": 1.2162162162162158, \"y\": 0.30868888085213003}, {\"x\": 1.2262262262262258, \"y\": 0.30646834771573817}, {\"x\": 1.2362362362362358, \"y\": 0.30423330204266075}, {\"x\": 1.2462462462462458, \"y\": 0.3019842959203774}, {\"x\": 1.2562562562562558, \"y\": 0.29972188156354207}, {\"x\": 1.2662662662662658, \"y\": 0.29744661109255016}, {\"x\": 1.2762762762762758, \"y\": 0.29515903631380075}, {\"x\": 1.2862862862862858, \"y\": 0.29285970850177234}, {\"x\": 1.2962962962962958, \"y\": 0.2905491781830298}, {\"x\": 1.3063063063063058, \"y\": 0.28822799492227513}, {\"x\": 1.3163163163163158, \"y\": 0.28589670711055704}, {\"x\": 1.3263263263263259, \"y\": 0.28355586175574593}, {\"x\": 1.3363363363363359, \"y\": 0.2812060042753844}, {\"x\": 1.3463463463463459, \"y\": 0.2788476782920163}, {\"x\": 1.3563563563563559, \"y\": 0.2764814254310975}, {\"x\": 1.3663663663663659, \"y\": 0.2741077851215873}, {\"x\": 1.3763763763763759, \"y\": 0.2717272943993179}, {\"x\": 1.386386386386386, \"y\": 0.26934048771323627}, {\"x\": 1.396396396396396, \"y\": 0.2669478967346085}, {\"x\": 1.406406406406406, \"y\": 0.26455005016927635}, {\"x\": 1.4164164164164168, \"y\": 0.26214747357305135}, {\"x\": 1.4264264264264268, \"y\": 0.2597406891703291}, {\"x\": 1.4364364364364368, \"y\": 0.2573302156760016}, {\"x\": 1.4464464464464468, \"y\": 0.25491656812074776}, {\"x\": 1.4564564564564568, \"y\": 0.25250025767977224}, {\"x\": 1.4664664664664668, \"y\": 0.25008179150506527}, {\"x\": 1.4764764764764768, \"y\": 0.24766167256124944}, {\"x\": 1.4864864864864868, \"y\": 0.24524039946507867}, {\"x\": 1.4964964964964969, \"y\": 0.2428184663286495}, {\"x\": 1.5065065065065069, \"y\": 0.24039636260638372}, {\"x\": 1.5165165165165169, \"y\": 0.2379745729458353}, {\"x\": 1.5265265265265269, \"y\": 0.23555357704237506}, {\"x\": 1.5365365365365369, \"y\": 0.23313384949780006}, {\"x\": 1.5465465465465469, \"y\": 0.23071585968291272}, {\"x\": 1.556556556556557, \"y\": 0.22830007160411228}, {\"x\": 1.566566566566567, \"y\": 0.22588694377403634}, {\"x\": 1.576576576576577, \"y\": 0.22347692908628844}, {\"x\": 1.586586586586587, \"y\": 0.22107047469428337}, {\"x\": 1.596596596596597, \"y\": 0.2186680218942395}, {\"x\": 1.606606606606607, \"y\": 0.2162700060123434}, {\"x\": 1.616616616616617, \"y\": 0.21387685629610992}, {\"x\": 1.626626626626627, \"y\": 0.21148899580995642}, {\"x\": 1.636636636636637, \"y\": 0.20910684133500765}, {\"x\": 1.646646646646647, \"y\": 0.2067308032731449}, {\"x\": 1.656656656656657, \"y\": 0.20436128555530794}, {\"x\": 1.666666666666667, \"y\": 0.20199868555405884}, {\"x\": 1.676676676676677, \"y\": 0.19964339400040887}, {\"x\": 1.686686686686687, \"y\": 0.1972957949049121}, {\"x\": 1.696696696696697, \"y\": 0.19495626548302109}, {\"x\": 1.706706706706707, \"y\": 0.19262517608470137}, {\"x\": 1.716716716716717, \"y\": 0.1903028901282955}, {\"x\": 1.726726726726727, \"y\": 0.18798976403862666}, {\"x\": 1.736736736736737, \"y\": 0.18568614718932766}, {\"x\": 1.746746746746747, \"y\": 0.1833923818493789}, {\"x\": 1.756756756756757, \"y\": 0.181108803133836}, {\"x\": 1.766766766766767, \"y\": 0.17883573895872582}, {\"x\": 1.776776776776777, \"y\": 0.1765735100000851}, {\"x\": 1.786786786786787, \"y\": 0.17432242965711614}, {\"x\": 1.796796796796797, \"y\": 0.17208280401942844}, {\"x\": 1.806806806806807, \"y\": 0.16985493183833505}, {\"x\": 1.816816816816817, \"y\": 0.16763910450216912}, {\"x\": 1.826826826826827, \"y\": 0.16543560601558271}, {\"x\": 1.836836836836837, \"y\": 0.16324471298279042}, {\"x\": 1.846846846846847, \"y\": 0.16106669459471448}, {\"x\": 1.856856856856857, \"y\": 0.1589018126199894}, {\"x\": 1.866866866866867, \"y\": 0.1567503213997789}, {\"x\": 1.876876876876877, \"y\": 0.15461246784635876}, {\"x\": 1.886886886886887, \"y\": 0.15248849144541485}, {\"x\": 1.8968968968968971, \"y\": 0.150378624262005}, {\"x\": 1.9069069069069071, \"y\": 0.14828309095013115}, {\"x\": 1.9169169169169171, \"y\": 0.14620210876586676}, {\"x\": 1.9269269269269271, \"y\": 0.14413588758398177}, {\"x\": 1.9369369369369371, \"y\": 0.14208462991800722}, {\"x\": 1.9469469469469471, \"y\": 0.14004853094367864}, {\"x\": 1.9569569569569571, \"y\": 0.13802777852569723}, {\"x\": 1.9669669669669672, \"y\": 0.1360225532477445}, {\"x\": 1.9769769769769772, \"y\": 0.13403302844568715}, {\"x\": 1.9869869869869872, \"y\": 0.1320593702439052}, {\"x\": 1.9969969969969972, \"y\": 0.13010173759467725}, {\"x\": 2.007007007007007, \"y\": 0.1281602823205539}, {\"x\": 2.017017017017017, \"y\": 0.12623514915965062}, {\"x\": 2.027027027027027, \"y\": 0.12432647581378924}, {\"x\": 2.037037037037037, \"y\": 0.12243439299941751}, {\"x\": 2.047047047047047, \"y\": 0.12055902450123379}, {\"x\": 2.057057057057057, \"y\": 0.11870048722844484}, {\"x\": 2.067067067067067, \"y\": 0.11685889127358226}, {\"x\": 2.0770770770770772, \"y\": 0.115034339973804}, {\"x\": 2.0870870870870872, \"y\": 0.11322692997460568}, {\"x\": 2.0970970970970972, \"y\": 0.11143675129586625}, {\"x\": 2.1071071071071072, \"y\": 0.10966388740015277}, {\"x\": 2.1171171171171173, \"y\": 0.10790841526320703}, {\"x\": 2.1271271271271273, \"y\": 0.1061704054465385}, {\"x\": 2.1371371371371373, \"y\": 0.1044499221720464}, {\"x\": 2.1471471471471473, \"y\": 0.10274702339859365}, {\"x\": 2.1571571571571573, \"y\": 0.1010617609004561}, {\"x\": 2.1671671671671673, \"y\": 0.09939418034756943}, {\"x\": 2.1771771771771773, \"y\": 0.09774432138749706}, {\"x\": 2.1871871871871873, \"y\": 0.09611221772904135}, {\"x\": 2.1971971971971973, \"y\": 0.0944978972274218}, {\"x\": 2.2072072072072073, \"y\": 0.0929013819709428}, {\"x\": 2.2172172172172173, \"y\": 0.09132268836907513}, {\"x\": 2.2272272272272273, \"y\": 0.08976182724187408}, {\"x\": 2.2372372372372373, \"y\": 0.08821880391065931}, {\"x\": 2.2472472472472473, \"y\": 0.08669361828987995}, {\"x\": 2.2572572572572573, \"y\": 0.0851862649800909}, {\"x\": 2.2672672672672673, \"y\": 0.08369673336196494}, {\"x\": 2.2772772772772774, \"y\": 0.08222500769126746}, {\"x\": 2.2872872872872874, \"y\": 0.08077106719471985}, {\"x\": 2.2972972972972974, \"y\": 0.0793348861666795}, {\"x\": 2.3073073073073074, \"y\": 0.07791643406656383}, {\"x\": 2.3173173173173174, \"y\": 0.07651567561694773}, {\"x\": 2.3273273273273274, \"y\": 0.07513257090226343}, {\"x\": 2.3373373373373374, \"y\": 0.07376707546803385}, {\"x\": 2.3473473473473474, \"y\": 0.07241914042057006}, {\"x\": 2.3573573573573574, \"y\": 0.0710887125270656}, {\"x\": 2.3673673673673674, \"y\": 0.06977573431602063}, {\"x\": 2.3773773773773774, \"y\": 0.06848014417792993}, {\"x\": 2.3873873873873874, \"y\": 0.0672018764661702}, {\"x\": 2.3973973973973974, \"y\": 0.06594086159802269}, {\"x\": 2.4074074074074074, \"y\": 0.06469702615576865}, {\"x\": 2.4174174174174174, \"y\": 0.06347029298779584}, {\"x\": 2.4274274274274275, \"y\": 0.06226058130965577}, {\"x\": 2.4374374374374375, \"y\": 0.061067806805012635}, {\"x\": 2.4474474474474475, \"y\": 0.059891881726425476}, {\"x\": 2.4574574574574575, \"y\": 0.05873271499590711}, {\"x\": 2.4674674674674675, \"y\": 0.05759021230520405}, {\"x\": 2.4774774774774775, \"y\": 0.05646427621574312}, {\"x\": 2.4874874874874875, \"y\": 0.05535480625819174}, {\"x\": 2.4974974974974975, \"y\": 0.05426169903158013}, {\"x\": 2.5075075075075075, \"y\": 0.05318484830193502}, {\"x\": 2.5175175175175175, \"y\": 0.052124145100375566}, {\"x\": 2.5275275275275275, \"y\": 0.051079477820624115}, {\"x\": 2.5375375375375375, \"y\": 0.05005073231588483}, {\"x\": 2.5475475475475475, \"y\": 0.04903779199504584}, {\"x\": 2.5575575575575575, \"y\": 0.04804053791816037}, {\"x\": 2.5675675675675675, \"y\": 0.04705884889116539}, {\"x\": 2.5775775775775776, \"y\": 0.04609260155979623}, {\"x\": 2.5875875875875876, \"y\": 0.045141670502658035}, {\"x\": 2.5975975975975976, \"y\": 0.044205928323415626}, {\"x\": 2.6076076076076076, \"y\": 0.04328524574206519}, {\"x\": 2.6176176176176176, \"y\": 0.042379491685252436}, {\"x\": 2.6276276276276276, \"y\": 0.041488533375603195}, {\"x\": 2.6376376376376376, \"y\": 0.04061223642003385}, {\"x\": 2.6476476476476476, \"y\": 0.03975046489701057}, {\"x\": 2.6576576576576576, \"y\": 0.03890308144272737}, {\"x\": 2.6676676676676676, \"y\": 0.03806994733617472}, {\"x\": 2.6776776776776776, \"y\": 0.03725092258307154}, {\"x\": 2.6876876876876876, \"y\": 0.03644586599863498}, {\"x\": 2.6976976976976976, \"y\": 0.035654635289163523}, {\"x\": 2.7077077077077076, \"y\": 0.03487708713241072}, {\"x\": 2.7177177177177176, \"y\": 0.03411307725672741}, {\"x\": 2.7277277277277276, \"y\": 0.03336246051895261}, {\"x\": 2.7377377377377377, \"y\": 0.032625090981033805}, {\"x\": 2.7477477477477477, \"y\": 0.031900821985358825}, {\"x\": 2.7577577577577577, \"y\": 0.03118950622878312}, {\"x\": 2.7677677677677677, \"y\": 0.030490995835337042}, {\"x\": 2.7777777777777777, \"y\": 0.029805142427599362}, {\"x\": 2.7877877877877877, \"y\": 0.029131797196724273}, {\"x\": 2.7977977977977977, \"y\": 0.02847081097111037}, {\"x\": 2.8078078078078077, \"y\": 0.027822034283701384}, {\"x\": 2.8178178178178177, \"y\": 0.02718531743790968}, {\"x\": 2.8278278278278277, \"y\": 0.026560510572154382}, {\"x\": 2.8378378378378377, \"y\": 0.025947463723007484}, {\"x\": 2.8478478478478477, \"y\": 0.025346026886942246}, {\"x\": 2.8578578578578577, \"y\": 0.024756050080679305}, {\"x\": 2.8678678678678677, \"y\": 0.024177383400127005}, {\"x\": 2.8778778778778777, \"y\": 0.0236098770779135}, {\"x\": 2.8878878878878878, \"y\": 0.023053381539509293}, {\"x\": 2.8978978978978978, \"y\": 0.022507747457939667}, {\"x\": 2.9079079079079078, \"y\": 0.021972825807087766}, {\"x\": 2.9179179179179178, \"y\": 0.021448467913589855}, {\"x\": 2.9279279279279278, \"y\": 0.02093452550732507}, {\"x\": 2.937937937937938, \"y\": 0.02043085077050338}, {\"x\": 2.947947947947948, \"y\": 0.019937296385355744}, {\"x\": 2.957957957957958, \"y\": 0.019453715580431883}, {\"x\": 2.967967967967968, \"y\": 0.018979962175511473}, {\"x\": 2.977977977977978, \"y\": 0.018515890625135766}, {\"x\": 2.987987987987988, \"y\": 0.018061356060767073}, {\"x\": 2.997997997997998, \"y\": 0.017616214331584626}, {\"x\": 3.0080080080080087, \"y\": 0.01718032204392579}, {\"x\": 3.0180180180180187, \"y\": 0.016753536599382828}, {\"x\": 3.0280280280280287, \"y\": 0.016335716231564996}, {\"x\": 3.0380380380380387, \"y\": 0.015926720041538035}, {\"x\": 3.0480480480480487, \"y\": 0.015526408031952323}, {\"x\": 3.0580580580580587, \"y\": 0.015134641139872246}, {\"x\": 3.0680680680680688, \"y\": 0.014751281268319889}, {\"x\": 3.0780780780780788, \"y\": 0.014376191316546608}, {\"x\": 3.0880880880880888, \"y\": 0.014009235209046558}, {\"x\": 3.0980980980980988, \"y\": 0.013650277923326943}, {\"x\": 3.108108108108109, \"y\": 0.013299185516449935}, {\"x\": 3.118118118118119, \"y\": 0.012955825150362083}, {\"x\": 3.128128128128129, \"y\": 0.012620065116027049}, {\"x\": 3.138138138138139, \"y\": 0.01229177485637829}, {\"x\": 3.148148148148149, \"y\": 0.011970824988108376}, {\"x\": 3.158158158158159, \"y\": 0.011657087322312343}, {\"x\": 3.168168168168169, \"y\": 0.011350434884002463}, {\"x\": 3.178178178178179, \"y\": 0.01105074193051245}, {\"x\": 3.188188188188189, \"y\": 0.010757883968809213}, {\"x\": 3.198198198198199, \"y\": 0.010471737771730707}, {\"x\": 3.208208208208209, \"y\": 0.01019218139316849}, {\"x\": 3.218218218218219, \"y\": 0.00991909418221403}, {\"x\": 3.228228228228229, \"y\": 0.009652356796287924}, {\"x\": 3.238238238238239, \"y\": 0.009391851213271359}, {\"x\": 3.248248248248249, \"y\": 0.009137460742659373}, {\"x\": 3.258258258258259, \"y\": 0.00888907003575564}, {\"x\": 3.268268268268269, \"y\": 0.008646565094928508}, {\"x\": 3.278278278278279, \"y\": 0.008409833281948323}, {\"x\": 3.288288288288289, \"y\": 0.008178763325426055}, {\"x\": 3.298298298298299, \"y\": 0.007953245327373232}, {\"x\": 3.308308308308309, \"y\": 0.007733170768903502}, {\"x\": 3.318318318318319, \"y\": 0.007518432515095917}, {\"x\": 3.328328328328329, \"y\": 0.007308924819040198}, {\"x\": 3.338338338338339, \"y\": 0.007104543325084221}, {\"x\": 3.348348348348349, \"y\": 0.006905185071303971}, {\"x\": 3.358358358358359, \"y\": 0.006710748491216124}, {\"x\": 3.368368368368369, \"y\": 0.006521133414753452}, {\"x\": 3.378378378378379, \"y\": 0.0063362410685231406}, {\"x\": 3.388388388388389, \"y\": 0.006155974075368084}, {\"x\": 3.398398398398399, \"y\": 0.005980236453251055}, {\"x\": 3.408408408408409, \"y\": 0.005808933613481662}, {\"x\": 3.418418418418419, \"y\": 0.005641972358305841}, {\"x\": 3.428428428428429, \"y\": 0.005479260877877461}, {\"x\": 3.438438438438439, \"y\": 0.005320708746631577}, {\"x\": 3.448448448448449, \"y\": 0.005166226919078649}, {\"x\": 3.458458458458459, \"y\": 0.0050157277250389605}, {\"x\": 3.468468468468469, \"y\": 0.004869124864336211}, {\"x\": 3.478478478478479, \"y\": 0.004726333400969128}, {\"x\": 3.488488488488489, \"y\": 0.004587269756779805}, {\"x\": 3.498498498498499, \"y\": 0.00445185170463717}, {\"x\": 3.508508508508509, \"y\": 0.004319998361153874}, {\"x\": 3.518518518518519, \"y\": 0.004191630178954622}, {\"x\": 3.528528528528529, \"y\": 0.004066668938513786}, {\"x\": 3.538538538538539, \"y\": 0.00394503773957986}, {\"x\": 3.548548548548549, \"y\": 0.0038266609922041513}, {\"x\": 3.558558558558559, \"y\": 0.003711464407390778}, {\"x\": 3.568568568568569, \"y\": 0.0035993749873848607}, {\"x\": 3.578578578578579, \"y\": 0.0034903210156155026}, {\"x\": 3.588588588588589, \"y\": 0.003384232046309918}, {\"x\": 3.598598598598599, \"y\": 0.003281038893794773}, {\"x\": 3.608608608608609, \"y\": 0.003180673621500546}, {\"x\": 3.618618618618619, \"y\": 0.0030830695306844624}, {\"x\": 3.628628628628629, \"y\": 0.002988161148887247}, {\"x\": 3.638638638638639, \"y\": 0.0028958842181386712}, {\"x\": 3.648648648648649, \"y\": 0.002806175682926569}, {\"x\": 3.658658658658659, \"y\": 0.0027189736779437627}, {\"x\": 3.668668668668669, \"y\": 0.0026342175156269516}, {\"x\": 3.678678678678679, \"y\": 0.0025518476735014424}, {\"x\": 3.688688688688689, \"y\": 0.002471805781345188}, {\"x\": 3.698698698698699, \"y\": 0.0023940346081854067}, {\"x\": 3.708708708708709, \"y\": 0.0023184780491406765}, {\"x\": 3.718718718718719, \"y\": 0.0022450811121211673}, {\"x\": 3.728728728728729, \"y\": 0.0021737899043993056}, {\"x\": 3.738738738738739, \"y\": 0.0021045516190629503}, {\"x\": 3.748748748748749, \"y\": 0.002037314521362766}, {\"x\": 3.758758758758759, \"y\": 0.0019720279349652713}, {\"x\": 3.768768768768769, \"y\": 0.0019086422281226671}, {\"x\": 3.778778778778779, \"y\": 0.0018471087997703002}, {\"x\": 3.788788788788789, \"y\": 0.0017873800655622933}, {\"x\": 3.7987987987987992, \"y\": 0.001729409443855605}, {\"x\": 3.8088088088088092, \"y\": 0.0016731513416524501}, {\"x\": 3.8188188188188192, \"y\": 0.0016185611405107503}, {\"x\": 3.8288288288288292, \"y\": 0.0015655951824319824}, {\"x\": 3.8388388388388393, \"y\": 0.0015142107557355158}, {\"x\": 3.8488488488488493, \"y\": 0.001464366080928198}, {\"x\": 3.8588588588588593, \"y\": 0.0014160202965777437}, {\"x\": 3.8688688688688693, \"y\": 0.0013691334451981186}, {\"x\": 3.8788788788788793, \"y\": 0.0013236664591548821}, {\"x\": 3.8888888888888893, \"y\": 0.0012795811465981665}, {\"x\": 3.8988988988988993, \"y\": 0.0012368401774306786}, {\"x\": 3.9089089089089093, \"y\": 0.0011954070693178706}, {\"x\": 3.9189189189189193, \"y\": 0.0011552461737471384}, {\"x\": 3.9289289289289293, \"y\": 0.0011163226621426366}, {\"x\": 3.9389389389389393, \"y\": 0.0010786025120420862}, {\"x\": 3.9489489489489493, \"y\": 0.001042052493341622}, {\"x\": 3.9589589589589593, \"y\": 0.0010066401546145458}, {\"x\": 3.9689689689689693, \"y\": 0.0009723338095095592}, {\"x\": 3.9789789789789793, \"y\": 0.0009391025232338248}, {\"x\": 3.9889889889889893, \"y\": 0.0009069160991259537}, {\"x\": 3.9989989989989994, \"y\": 0.0008757450653237962}, {\"x\": 4.009009009009009, \"y\": 0.0008455606615316683}, {\"x\": 4.019019019019019, \"y\": 0.0008163348258914237}, {\"x\": 4.029029029029029, \"y\": 0.0007880401819615562}, {\"x\": 4.039039039039039, \"y\": 0.0007606500258083074}, {\"x\": 4.049049049049049, \"y\": 0.0007341383132125242}, {\"x\": 4.059059059059059, \"y\": 0.0007084796469958226}, {\"x\": 4.069069069069069, \"y\": 0.0006836492644693825}, {\"x\": 4.079079079079079, \"y\": 0.0006596230250085266}, {\"x\": 4.089089089089089, \"y\": 0.0006363773977560138}, {\"x\": 4.099099099099099, \"y\": 0.0006138894494568069}, {\"x\": 4.109109109109109, \"y\": 0.0005921368324268691}, {\"x\": 4.119119119119119, \"y\": 0.0005710977726583803}, {\"x\": 4.129129129129129, \"y\": 0.0005507510580635691}, {\"x\": 4.1391391391391394, \"y\": 0.0005310760268591873}, {\"x\": 4.1491491491491495, \"y\": 0.0005120525560935024}, {\"x\": 4.1591591591591595, \"y\": 0.000493661050317485}, {\"x\": 4.1691691691691695, \"y\": 0.0004758824304017402}, {\"x\": 4.1791791791791795, \"y\": 0.0004586981225005626}, {\"x\": 4.1891891891891895, \"y\": 0.00044209004716434173}, {\"x\": 4.1991991991991995, \"y\": 0.0004260406086014023}, {\"x\": 4.2092092092092095, \"y\": 0.0004105326840902254}, {\"x\": 4.2192192192192195, \"y\": 0.00039554961354284904}, {\"x\": 4.2292292292292295, \"y\": 0.00038107518922012474}, {\"x\": 4.2392392392392395, \"y\": 0.00036709364559936697}, {\"x\": 4.2492492492492495, \"y\": 0.0003535896493948167}, {\"x\": 4.2592592592592595, \"y\": 0.00034054828973121654}, {\"x\": 4.2692692692692695, \"y\": 0.00032795506847067303}, {\"x\": 4.2792792792792795, \"y\": 0.00031579589069288003}, {\"x\": 4.2892892892892895, \"y\": 0.0003040570553286624}, {\"x\": 4.2992992992992995, \"y\": 0.00029272524594669365}, {\"x\": 4.3093093093093096, \"y\": 0.00028178752169314835}, {\"x\": 4.31931931931932, \"y\": 0.0002712313083839442}, {\"x\": 4.32932932932933, \"y\": 0.00026104438974914647}, {\"x\": 4.33933933933934, \"y\": 0.0002512148988290113}, {\"x\": 4.34934934934935, \"y\": 0.0002417313095210609}, {\"x\": 4.35935935935936, \"y\": 0.00023258242827750735}, {\"x\": 4.36936936936937, \"y\": 0.0002237573859522578}, {\"x\": 4.37937937937938, \"y\": 0.00021524562979666328}, {\"x\": 4.38938938938939, \"y\": 0.00020703691560310116}, {\"x\": 4.3993993993994, \"y\": 0.00019912129999541647}, {\"x\": 4.40940940940941, \"y\": 0.0001914891328651794}, {\"x\": 4.41941941941942, \"y\": 0.00018413104995265942}, {\"x\": 4.42942942942943, \"y\": 0.0001770379655713583}, {\"x\": 4.43943943943944, \"y\": 0.00017020106547488485}, {\"x\": 4.44944944944945, \"y\": 0.00016361179986491348}, {\"x\": 4.45945945945946, \"y\": 0.0001572618765389067}, {\"x\": 4.46946946946947, \"y\": 0.00015114325417625064}, {\"x\": 4.47947947947948, \"y\": 0.00014524813576139527}, {\"x\": 4.48948948948949, \"y\": 0.00013956896214256578}, {\"x\": 4.4994994994995, \"y\": 0.00013409840572456105}, {\"x\": 4.50950950950951, \"y\": 0.00012882936429412978}, {\"x\": 4.51951951951952, \"y\": 0.0001237549549763804}, {\"x\": 4.52952952952953, \"y\": 0.00011886850832064561}, {\"x\": 4.53953953953954, \"y\": 0.00011416356251420682}, {\"x\": 4.54954954954955, \"y\": 0.00010963385772224669}, {\"x\": 4.55955955955956, \"y\": 0.00010527333055238145}, {\"x\": 4.56956956956957, \"y\": 0.00010107610864210718}, {\"x\": 4.57957957957958, \"y\": 9.703650536746718e-05}, {\"x\": 4.58958958958959, \"y\": 9.314901467123951e-05}, {\"x\": 4.5995995995996, \"y\": 8.940830600892605e-05}, {\"x\": 4.60960960960961, \"y\": 8.580921941081053e-05}, {\"x\": 4.61961961961962, \"y\": 8.234676065834611e-05}, {\"x\": 4.62962962962963, \"y\": 7.901609657312171e-05}, {\"x\": 4.63963963963964, \"y\": 7.581255041665056e-05}, {\"x\": 4.64964964964965, \"y\": 7.273159739921756e-05}, {\"x\": 4.65965965965966, \"y\": 6.976886029602065e-05}, {\"x\": 4.66966966966967, \"y\": 6.69201051688371e-05}, {\"x\": 4.67967967967968, \"y\": 6.41812371914466e-05}, {\"x\": 4.68968968968969, \"y\": 6.154829657704137e-05}, {\"x\": 4.6996996996997, \"y\": 5.9017454605858465e-05}, {\"x\": 4.70970970970971, \"y\": 5.658500975127081e-05}, {\"x\": 4.71971971971972, \"y\": 5.424738390257894e-05}, {\"x\": 4.72972972972973, \"y\": 5.200111868275023e-05}, {\"x\": 4.73973973973974, \"y\": 4.984287185936102e-05}, {\"x\": 4.74974974974975, \"y\": 4.776941384700376e-05}, {\"x\": 4.75975975975976, \"y\": 4.5777624299430246e-05}, {\"x\": 4.76976976976977, \"y\": 4.386448878971312e-05}, {\"x\": 4.77977977977978, \"y\": 4.2027095576717835e-05}, {\"x\": 4.78978978978979, \"y\": 4.026263245618972e-05}, {\"x\": 4.7997997997998, \"y\": 3.856838369477261e-05}, {\"x\": 4.80980980980981, \"y\": 3.694172704529014e-05}, {\"x\": 4.81981981981982, \"y\": 3.53801308416342e-05}, {\"x\": 4.82982982982983, \"y\": 3.3881151171620486e-05}, {\"x\": 4.83983983983984, \"y\": 3.244242912618571e-05}, {\"x\": 4.84984984984985, \"y\": 3.1061688123318675e-05}, {\"x\": 4.85985985985986, \"y\": 2.973673130513299e-05}, {\"x\": 4.86986986986987, \"y\": 2.8465439006507273e-05}, {\"x\": 4.87987987987988, \"y\": 2.7245766293735667e-05}, {\"x\": 4.88988988988989, \"y\": 2.607574057165087e-05}, {\"x\": 4.8998998998999, \"y\": 2.495345925769959e-05}, {\"x\": 4.90990990990991, \"y\": 2.38770875214702e-05}, {\"x\": 4.91991991991992, \"y\": 2.284485608819101e-05}, {\"x\": 4.92992992992993, \"y\": 2.185505910473813e-05}, {\"x\": 4.93993993993994, \"y\": 2.0906052066711778e-05}, {\"x\": 4.94994994994995, \"y\": 1.999624980515957e-05}, {\"x\": 4.95995995995996, \"y\": 1.9124124531546972e-05}, {\"x\": 4.96996996996997, \"y\": 1.828820393959499e-05}, {\"x\": 4.97997997997998, \"y\": 1.7487069362626764e-05}, {\"x\": 4.98998998998999, \"y\": 1.6719353985085165e-05}, {\"x\": 5.0, \"y\": 1.5983741106905475e-05}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def normal_pdf(x, mu, sigma):\n",
    "    return 1 / np.sqrt(2 * np.pi * sigma**2) * np.exp(-(x - mu)**2 / (2 * sigma**2))\n",
    "\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "df = pd.DataFrame({'x': x, 'y': normal_pdf(x, 0.5, 1)})\n",
    "alt.Chart(df).mark_line().encode(x='x', y='y')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing logistic regression from a generalized linear model perspective\n",
    "\n",
    "please create visualizations in altair for a jupyter notebook in the python programming language for the following key concepts in generalized linear models for logistic regression specifically\n",
    "\n",
    "> `What is the canonical reference for generalized linear model (GLM)`\n",
    "\n",
    "https://www.utstat.toronto.edu/~brunner/oldclass/2201s11/readings/glmbook.pdf \n",
    "\n",
    "\n",
    "In the McCullagh and Nelder formulation, the generalized linear model is defined in terms of a systematic component and a random component. Logistic regression is a type of generalized linear model (GLM) where the outcome is binary. \n",
    "\n",
    "The systematic component for a binary logistic regression model can be written as:\n",
    "\n",
    "$$\n",
    "\\eta = X\\beta\n",
    "$$\n",
    "\n",
    "where X is the design matrix,  is the vector of parameters to be estimated, and  is the linear predictor.\n",
    "\n",
    "The logistic regression model specifically uses the logit link function, which connects the systematic and random components. This function is the natural logarithm of the odds, and can be written as:\n",
    "\n",
    "$$ \n",
    "g(\\mu) = \\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\eta\n",
    "$$\n",
    "\n",
    "where  represents the expected value of the response variable.\n",
    "\n",
    "Therefore, the logistic regression model can be written as:\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = X\\beta\n",
    "$$\n",
    "\n",
    "where:\n",
    "-  is the expected value of the response variable, given the predictors\n",
    "- X is the matrix of predictors\n",
    "-  is the vector of parameters to be estimated\n",
    "\n",
    "Finally, solving the equation for  gives the standard form of the logistic regression model:\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{1 + \\exp(-X\\beta)}\n",
    "$$\n",
    "\n",
    "This gives the probability of the positive class in a binary logistic regression model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, below is the corresponding raw LaTeX for the code you provided. This includes the equations used in the code, and not the code itself, as LaTeX is not intended for representing programming code. \n",
    "\n",
    "The linear predictor, the logistic function, and the logistic regression model can be represented as follows in LaTeX:\n",
    "\n",
    "**1. The Linear Predictor:**\n",
    "\n",
    "This is simply a linear combination of the predictors.\n",
    "\n",
    "$$\n",
    "\\eta = \\beta_0 + \\beta_1 x\n",
    "$$\n",
    "Where:\n",
    "- `\\eta` is the linear predictor\n",
    "- `\\beta_0` is the intercept\n",
    "- `\\beta_1` is the coefficient for the predictor `x`\n",
    "\n",
    "**2. The Logistic Function:**\n",
    "\n",
    "This maps the linear predictor onto the interval (0, 1) as a probability. \n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{1 + e^{-\\eta}}\n",
    "$$\n",
    "Where:\n",
    "- `\\mu` is the probability of the positive class\n",
    "- `\\eta` is the linear predictor\n",
    "\n",
    "**3. The Logistic Regression Model:**\n",
    "\n",
    "The logistic regression model combines these two components.\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}\n",
    "$$\n",
    "Where:\n",
    "- `\\mu` is the probability of the positive class\n",
    "- `\\beta_0` is the intercept\n",
    "- `\\beta_1` is the coefficient for the predictor `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-23ac81ea35b445128e78891b91bf2bf8\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-23ac81ea35b445128e78891b91bf2bf8\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-23ac81ea35b445128e78891b91bf2bf8\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-4f034231542452d9fe045f2e68bf4235\"}, \"mark\": \"line\", \"encoding\": {\"x\": {\"field\": \"x\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"eta\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-4f034231542452d9fe045f2e68bf4235\": [{\"x\": -10.0, \"eta\": -8.0}, {\"x\": -9.797979797979798, \"eta\": -7.797979797979798}, {\"x\": -9.595959595959595, \"eta\": -7.595959595959595}, {\"x\": -9.393939393939394, \"eta\": -7.3939393939393945}, {\"x\": -9.191919191919192, \"eta\": -7.191919191919192}, {\"x\": -8.98989898989899, \"eta\": -6.98989898989899}, {\"x\": -8.787878787878787, \"eta\": -6.787878787878787}, {\"x\": -8.585858585858587, \"eta\": -6.5858585858585865}, {\"x\": -8.383838383838384, \"eta\": -6.383838383838384}, {\"x\": -8.181818181818182, \"eta\": -6.181818181818182}, {\"x\": -7.979797979797979, \"eta\": -5.979797979797979}, {\"x\": -7.777777777777778, \"eta\": -5.777777777777778}, {\"x\": -7.575757575757576, \"eta\": -5.575757575757576}, {\"x\": -7.373737373737374, \"eta\": -5.373737373737374}, {\"x\": -7.171717171717171, \"eta\": -5.171717171717171}, {\"x\": -6.96969696969697, \"eta\": -4.96969696969697}, {\"x\": -6.767676767676768, \"eta\": -4.767676767676768}, {\"x\": -6.565656565656566, \"eta\": -4.565656565656566}, {\"x\": -6.363636363636363, \"eta\": -4.363636363636363}, {\"x\": -6.161616161616162, \"eta\": -4.161616161616162}, {\"x\": -5.959595959595959, \"eta\": -3.9595959595959593}, {\"x\": -5.757575757575758, \"eta\": -3.757575757575758}, {\"x\": -5.555555555555555, \"eta\": -3.5555555555555554}, {\"x\": -5.353535353535354, \"eta\": -3.353535353535354}, {\"x\": -5.151515151515151, \"eta\": -3.1515151515151514}, {\"x\": -4.94949494949495, \"eta\": -2.94949494949495}, {\"x\": -4.747474747474747, \"eta\": -2.7474747474747474}, {\"x\": -4.545454545454546, \"eta\": -2.545454545454546}, {\"x\": -4.343434343434343, \"eta\": -2.3434343434343434}, {\"x\": -4.141414141414142, \"eta\": -2.141414141414142}, {\"x\": -3.9393939393939394, \"eta\": -1.9393939393939394}, {\"x\": -3.737373737373738, \"eta\": -1.737373737373738}, {\"x\": -3.5353535353535355, \"eta\": -1.5353535353535355}, {\"x\": -3.333333333333333, \"eta\": -1.333333333333333}, {\"x\": -3.1313131313131315, \"eta\": -1.1313131313131315}, {\"x\": -2.929292929292929, \"eta\": -0.9292929292929291}, {\"x\": -2.7272727272727275, \"eta\": -0.7272727272727275}, {\"x\": -2.525252525252525, \"eta\": -0.5252525252525251}, {\"x\": -2.3232323232323235, \"eta\": -0.32323232323232354}, {\"x\": -2.121212121212121, \"eta\": -0.1212121212121211}, {\"x\": -1.9191919191919187, \"eta\": 0.08080808080808133}, {\"x\": -1.717171717171718, \"eta\": 0.282828282828282}, {\"x\": -1.5151515151515156, \"eta\": 0.4848484848484844}, {\"x\": -1.3131313131313131, \"eta\": 0.6868686868686869}, {\"x\": -1.1111111111111107, \"eta\": 0.8888888888888893}, {\"x\": -0.9090909090909101, \"eta\": 1.09090909090909}, {\"x\": -0.7070707070707076, \"eta\": 1.2929292929292924}, {\"x\": -0.5050505050505052, \"eta\": 1.4949494949494948}, {\"x\": -0.30303030303030276, \"eta\": 1.6969696969696972}, {\"x\": -0.10101010101010033, \"eta\": 1.8989898989898997}, {\"x\": 0.10101010101010033, \"eta\": 2.1010101010101003}, {\"x\": 0.30303030303030276, \"eta\": 2.3030303030303028}, {\"x\": 0.5050505050505052, \"eta\": 2.505050505050505}, {\"x\": 0.7070707070707076, \"eta\": 2.7070707070707076}, {\"x\": 0.9090909090909083, \"eta\": 2.9090909090909083}, {\"x\": 1.1111111111111107, \"eta\": 3.1111111111111107}, {\"x\": 1.3131313131313131, \"eta\": 3.313131313131313}, {\"x\": 1.5151515151515156, \"eta\": 3.5151515151515156}, {\"x\": 1.7171717171717162, \"eta\": 3.7171717171717162}, {\"x\": 1.9191919191919187, \"eta\": 3.9191919191919187}, {\"x\": 2.121212121212121, \"eta\": 4.121212121212121}, {\"x\": 2.3232323232323235, \"eta\": 4.3232323232323235}, {\"x\": 2.525252525252524, \"eta\": 4.525252525252524}, {\"x\": 2.7272727272727266, \"eta\": 4.727272727272727}, {\"x\": 2.929292929292929, \"eta\": 4.929292929292929}, {\"x\": 3.1313131313131315, \"eta\": 5.1313131313131315}, {\"x\": 3.333333333333334, \"eta\": 5.333333333333334}, {\"x\": 3.5353535353535346, \"eta\": 5.535353535353535}, {\"x\": 3.737373737373737, \"eta\": 5.737373737373737}, {\"x\": 3.9393939393939394, \"eta\": 5.9393939393939394}, {\"x\": 4.141414141414142, \"eta\": 6.141414141414142}, {\"x\": 4.3434343434343425, \"eta\": 6.3434343434343425}, {\"x\": 4.545454545454545, \"eta\": 6.545454545454545}, {\"x\": 4.747474747474747, \"eta\": 6.747474747474747}, {\"x\": 4.94949494949495, \"eta\": 6.94949494949495}, {\"x\": 5.1515151515151505, \"eta\": 7.1515151515151505}, {\"x\": 5.353535353535353, \"eta\": 7.353535353535353}, {\"x\": 5.555555555555555, \"eta\": 7.555555555555555}, {\"x\": 5.757575757575758, \"eta\": 7.757575757575758}, {\"x\": 5.9595959595959584, \"eta\": 7.9595959595959584}, {\"x\": 6.161616161616163, \"eta\": 8.161616161616163}, {\"x\": 6.363636363636363, \"eta\": 8.363636363636363}, {\"x\": 6.565656565656564, \"eta\": 8.565656565656564}, {\"x\": 6.767676767676768, \"eta\": 8.767676767676768}, {\"x\": 6.969696969696969, \"eta\": 8.969696969696969}, {\"x\": 7.171717171717173, \"eta\": 9.171717171717173}, {\"x\": 7.373737373737374, \"eta\": 9.373737373737374}, {\"x\": 7.575757575757574, \"eta\": 9.575757575757574}, {\"x\": 7.777777777777779, \"eta\": 9.777777777777779}, {\"x\": 7.979797979797979, \"eta\": 9.97979797979798}, {\"x\": 8.18181818181818, \"eta\": 10.18181818181818}, {\"x\": 8.383838383838384, \"eta\": 10.383838383838384}, {\"x\": 8.585858585858585, \"eta\": 10.585858585858585}, {\"x\": 8.787878787878789, \"eta\": 10.787878787878789}, {\"x\": 8.98989898989899, \"eta\": 10.98989898989899}, {\"x\": 9.19191919191919, \"eta\": 11.19191919191919}, {\"x\": 9.393939393939394, \"eta\": 11.393939393939394}, {\"x\": 9.595959595959595, \"eta\": 11.595959595959595}, {\"x\": 9.7979797979798, \"eta\": 11.7979797979798}, {\"x\": 10.0, \"eta\": 12.0}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "# Define the parameters for our model\n",
    "beta = np.array([1, 2])\n",
    "\n",
    "# Create a grid of x values\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "# Create a DataFrame with the x values and their corresponding eta values\n",
    "df = pd.DataFrame({\n",
    "    'x': x,\n",
    "    'eta': x * beta[0] + beta[1]\n",
    "})\n",
    "\n",
    "# Create the Altair chart\n",
    "chart = alt.Chart(df).mark_line().encode(\n",
    "    x='x',\n",
    "    y='eta'\n",
    ")\n",
    "\n",
    "chart\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for chat messages\n",
    "\n",
    "Sure, let's consider the following hypothetical scenario:\n",
    "\n",
    "We are building a logistic regression model to predict whether a chat message is spam (1) or not spam (0) based on the number of links in the message. We have two parameters, the intercept `0` and the coefficient for the number of links `1`.\n",
    "\n",
    "We can represent the key components of the logistic regression model with this specific example as follows:\n",
    "\n",
    "**1. The Linear Predictor:**\n",
    "\n",
    "This is the linear combination of the predictor (number of links). Suppose our intercept `0` is -3 and our coefficient `1` is 2.5.\n",
    "\n",
    "$$\n",
    "\\eta = \\beta_0 + \\beta_1 * \\text{{number of links}} = -3 + 2.5 * \\text{{number of links}}\n",
    "$$\n",
    "**2. The Logistic Function:**\n",
    "\n",
    "This maps the linear predictor onto the interval (0, 1) as a probability.\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{1 + e^{-\\eta}} = \\frac{1}{1 + e^{-(-3 + 2.5 * \\text{{number of links}})}}\n",
    "$$\n",
    "**3. The Logistic Regression Model:**\n",
    "\n",
    "The logistic regression model combines these two components, predicting the probability that a message is spam based on the number of links it contains.\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{1 + e^{-(-3 + 2.5 * \\text{{number of links}})}}\n",
    "$$\n",
    "So, in this case, `` represents the predicted probability that a message is spam, given the number of links in the message."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of being ultra-prescriptive to connect the historical symbols/words/concepts in Mcullaugh and Nelder to the modern symbols/words/concepts in the lecture note\n",
    "\n",
    "> Sorry this isn't quite the same formalism. We need to be ultra-prescriptive here so please try again using the same mathematical notation, symbols, and style of this lecture note from previous class that you generated for us: \n",
    "\n",
    "Apologies for the confusion earlier. Let's use a more prescriptive approach by working through a specific example, using the same notation and symbols from the lecture note.\n",
    "\n",
    "Suppose we want to build a model to predict if a chat message is spam (1) or not spam (0) based on the number of links (`x1`) and the length of the message in characters (`x2`). Our design matrix `X` will then include these two features, and our vector `` of parameters will contain two coefficients, `1` and `2`, which we wish to estimate.\n",
    "\n",
    "The systematic component (linear predictor ``) can be written as:\n",
    "\n",
    "$$\n",
    "\\eta = X\\beta = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\n",
    "$$\n",
    "where:\n",
    "\n",
    "- `x1` is the number of links in the chat message\n",
    "- `x2` is the length of the message\n",
    "- `0` is the intercept\n",
    "- `1` is the coefficient for the number of links (`x1`)\n",
    "- `2` is the coefficient for the message length (`x2`)\n",
    "\n",
    "The logistic regression model uses the logit link function, which connects the systematic and random components:\n",
    "\n",
    "$$\n",
    "g(\\mu) = \\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\eta = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\n",
    "$$\n",
    "where `` represents the expected value (probability of being spam) given the predictors (number of links and message length).\n",
    "\n",
    "Therefore, the logistic regression model can be written as:\n",
    "\n",
    "$$\n",
    "\\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\n",
    "$$\n",
    "where:\n",
    "\n",
    "- `` is the expected value (probability of being spam), given the predictors\n",
    "- `x1` and `x2` are our predictors (number of links and message length, respectively)\n",
    "- `0`, `1`, and `2` are the parameters to be estimated\n",
    "\n",
    "Finally, solving this equation for `` gives the standard form of the logistic regression model:\n",
    "\n",
    "$$\n",
    "\\mu = \\frac{1}{1 + \\exp(-(\\beta_0 + \\beta_1x_1 + \\beta_2x_2))}\n",
    "$$\n",
    "This equation will give us the probability that a chat message is spam, given its number of links and its length.\n",
    "\n",
    "Here are the steps to solving this "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: steps to solving for the link function to get to he standard formr of logistic regression\n",
    "First, we start with the logit link function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\log\\left(\\frac{\\mu}{1 - \\mu}\\right) = \\beta_0 + \\beta_1x_1 + \\beta_2x_2\n",
    "\\end{equation}\n",
    "\n",
    "We then want to solve this equation for $\\mu$.\n",
    "\n",
    "Step 1: Take the exponential of both sides to remove the natural logarithm on the left side:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mu}{1 - \\mu} = \\exp(\\beta_0 + \\beta_1x_1 + \\beta_2x_2)\n",
    "\\end{equation}\n",
    "\n",
    "Step 2: Multiply both sides by $1 - \\mu$ to isolate $\\mu$ on one side:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu = (1 - \\mu) \\exp(\\beta_0 + \\beta_1x_1 + \\beta_2x_2)\n",
    "\\end{equation}\n",
    "\n",
    "Step 3: Distribute the right-hand side and bring all terms involving $\\mu$ to the left side:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu = \\exp(\\beta_0 + \\beta_1x_1 + \\beta_2x_2) - \\mu \\exp(\\beta_0 + \\beta_1x_1 + \\beta_2x_2)\n",
    "\\end{equation}\n",
    "\n",
    "Step 4: Simplify by collecting terms with $\\mu$ on one side:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu (1 + \\exp(\\beta_0 + \\beta_1x_1 + \\beta_2x_2)) = \\exp(\\beta_0 + \\beta_1x_1 + \\beta_2x_2)\n",
    "\\end{equation}\n",
    "\n",
    "Step 5: Finally, solve for $\\mu$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu = \\frac{\\exp(\\beta_0 + \\beta_1x_1 + \\beta_2x_2)}{1 + \\exp(\\beta_0 + \\beta_1x_1 + \\beta_2x_2)}\n",
    "\\end{equation}\n",
    "\n",
    "This simplifies to the standard form of the logistic regression model:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mu = \\frac{1}{1 + \\exp(-(\\beta_0 + \\beta_1x_1 + \\beta_2x_2))}\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on chat logs for the class\n",
    "\n",
    "-- figure out which columns/types are in a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      column_name        column_type   null      key    default   extra  \n",
      "        varchar            varchar    varchar  varchar  varchar  varchar \n",
      "\n",
      " id                      UBIGINT      YES                                \n",
      " sender                  UBIGINT      YES                                \n",
      " recipient               BIGINT       YES                                \n",
      " realm                   UBIGINT      YES                                \n",
      " subject                 VARCHAR      YES                                \n",
      " content                 VARCHAR      YES                                \n",
      " rendered_content        VARCHAR      YES                                \n",
      " rendered_content_ver   UBIGINT      YES                                \n",
      " date_sent               VARCHAR      YES                                \n",
      " sending_client          BIGINT       YES                                \n",
      " last_edit_time          VARCHAR      YES                                \n",
      " edit_history            VARCHAR      YES                                \n",
      " has_attachment          BOOLEAN      YES                                \n",
      " has_image               BOOLEAN      YES                                \n",
      " has_link                BOOLEAN      YES                                \n",
      " search_tsvector         VARCHAR      YES                                \n",
      "\n",
      " 16 rows                                                            6 columns \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!duckdb :memory: \"DESCRIBE SELECT * FROM './data/datathinking.zulipchat.com/processed/zerver_message.parquet'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " column_name   column_type   null      key    default   extra  \n",
      "   varchar       varchar    varchar  varchar  varchar  varchar \n",
      "\n",
      " id            UBIGINT      YES                                \n",
      " user_profile  UBIGINT      YES                                \n",
      " message       UBIGINT      YES                                \n",
      " flags_mask    BOOLEAN      YES                                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "!duckdb :memory: \"DESCRIBE SELECT * FROM './data/datathinking.zulipchat.com/processed/zerver_usermessage.parquet'\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example on chat logs for the class\n",
    "\n",
    "please generate code using jax to fit a logistic regression model using the above example and the same notation and variable names using the following schema for this parquet file that contains the data:\n",
    "\n",
    "!duckdb :memory: \"DESCRIBE SELECT * FROM './data/datathinking.zulipchat.com/processed/zerver_usermessage.parquet'\"\n",
    "\n",
    "```\n",
    "\n",
    " column_name   column_type   null      key    default   extra  \n",
    "   varchar       varchar    varchar  varchar  varchar  varchar \n",
    "\n",
    " id            UBIGINT      YES                                \n",
    " user_profile  UBIGINT      YES                                \n",
    " message       UBIGINT      YES                                \n",
    " flags_mask    BOOLEAN      YES                          \n",
    "```\n",
    "\n",
    "Based on your question, it seems like you want to use the fields user_profile and message as the predictors (features) and flags_mask as the binary target variable. For simplicity, let's assume flags_mask is our binary target with 1 indicating spam and 0 indicating not spam.\n",
    "\n",
    "Here is the Python code using JAX to fit a logistic regression model. Please note that the JAX library primarily works with arrays, not data frames, so the input data will need to be converted into this format.\n",
    "\n",
    "Please adjust learning_rate and epochs as needed. In addition, please install necessary dependencies (if not installed) before running this code. The above example assumes a very simple logistic regression model and does not include any feature scaling or selection, regularization, cross-validation, or other techniques that may be appropriate for a real-world application.\n",
    "\n",
    "Please replace the path to the parquet file with your actual path and ensure that your environment has enough memory to hold the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [nan nan]\n",
      "b: nan\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random\n",
    "from jax.scipy.special import expit as sigmoid\n",
    "from jax import grad, jit, vmap\n",
    "from jax import lax\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Read parquet file\n",
    "df = pd.read_parquet('./data/datathinking.zulipchat.com/processed/zerver_usermessage.parquet')\n",
    "\n",
    "# Ensure correct data types\n",
    "df = df.astype({\"user_profile\": 'float32', \"message\": 'float32', \"flags_mask\": 'int32'})\n",
    "\n",
    "# Define features and target\n",
    "X = df[['user_profile', 'message']].values\n",
    "y = df['flags_mask'].values\n",
    "\n",
    "# Initialize parameters randomly\n",
    "key = random.PRNGKey(0)\n",
    "key, W_key, b_key = random.split(key, 3)\n",
    "W = random.normal(W_key, (2,))\n",
    "b = random.normal(b_key, ())\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 0.5 * (np.tanh(x / 2) + 1)\n",
    "\n",
    "# Predict function\n",
    "def predict(W, b, inputs):\n",
    "    return sigmoid(np.dot(inputs, W) + b)\n",
    "\n",
    "# Loss function\n",
    "def loss(W, b, inputs, targets):\n",
    "    preds = predict(W, b, inputs)\n",
    "    label_probs = preds * targets + (1 - preds) * (1 - targets)\n",
    "    return -np.sum(np.log(label_probs))\n",
    "\n",
    "# Compute gradient of loss function\n",
    "grad_loss = jit(grad(loss, argnums=(0, 1)))\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "for i in range(epochs):\n",
    "    dW, db = grad_loss(W, b, X, y)\n",
    "    W -= learning_rate * dW\n",
    "    b -= learning_rate * db\n",
    "\n",
    "# Print final parameters\n",
    "print(\"W:\", W)\n",
    "print(\"b:\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_profile</th>\n",
       "      <th>message</th>\n",
       "      <th>flags_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8257034355</td>\n",
       "      <td>544719.0</td>\n",
       "      <td>299488064.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8257034356</td>\n",
       "      <td>544719.0</td>\n",
       "      <td>299488064.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8257034357</td>\n",
       "      <td>544719.0</td>\n",
       "      <td>299488064.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9332100997</td>\n",
       "      <td>587794.0</td>\n",
       "      <td>327255232.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9332100998</td>\n",
       "      <td>544719.0</td>\n",
       "      <td>327255232.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20325</th>\n",
       "      <td>9829132736</td>\n",
       "      <td>589802.0</td>\n",
       "      <td>342317088.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20326</th>\n",
       "      <td>9829132737</td>\n",
       "      <td>590314.0</td>\n",
       "      <td>342317088.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20327</th>\n",
       "      <td>9829132738</td>\n",
       "      <td>591344.0</td>\n",
       "      <td>342317088.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20328</th>\n",
       "      <td>9829132739</td>\n",
       "      <td>590323.0</td>\n",
       "      <td>342317088.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20329</th>\n",
       "      <td>9829132740</td>\n",
       "      <td>589822.0</td>\n",
       "      <td>342317088.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20330 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  user_profile      message  flags_mask\n",
       "0      8257034355      544719.0  299488064.0           1\n",
       "1      8257034356      544719.0  299488064.0           1\n",
       "2      8257034357      544719.0  299488064.0           1\n",
       "3      9332100997      587794.0  327255232.0           1\n",
       "4      9332100998      544719.0  327255232.0           1\n",
       "...           ...           ...          ...         ...\n",
       "20325  9829132736      589802.0  342317088.0           0\n",
       "20326  9829132737      590314.0  342317088.0           0\n",
       "20327  9829132738      591344.0  342317088.0           0\n",
       "20328  9829132739      590323.0  342317088.0           0\n",
       "20329  9829132740      589822.0  342317088.0           0\n",
       "\n",
       "[20330 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This was incorrect because I didn't read that `message` is a `BIGINT` datatype instead of a string like we need\n",
    "\n",
    "Had to remind GPT-4 to follow the example using prompts like `awesome. can you please rewrite to be as close to this example as possible and use the same notation as the latex you helped us generate for the math?` many times to get the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m beta_0 \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mnormal(b_key, ())  \u001b[39m# Intercept 0\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# Assume number of links and length of message are our predictors\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# For simplicity, let's generate these columns randomly as the actual computation might be more complex\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mx1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39;49mrandint(key\u001b[39m=\u001b[39;49mkey, minval\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, maxval\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, shape\u001b[39m=\u001b[39;49mdf\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])  \u001b[39m# Number of links\u001b[39;00m\n\u001b[1;32m     23\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mx2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mlen()  \u001b[39m# Length of message\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m# Ensure correct data types\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/datathinking.org/lib/python3.11/site-packages/jax/_src/random.py:325\u001b[0m, in \u001b[0;36mrandint\u001b[0;34m(key, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m    323\u001b[0m key, _ \u001b[39m=\u001b[39m _check_prng_key(key)\n\u001b[1;32m    324\u001b[0m dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mcanonicalize_dtype(dtype)\n\u001b[0;32m--> 325\u001b[0m shape \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mcanonicalize_shape(shape)\n\u001b[1;32m    326\u001b[0m \u001b[39mreturn\u001b[39;00m _randint(key, shape, minval, maxval, dtype)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/datathinking.org/lib/python3.11/site-packages/jax/_src/core.py:2009\u001b[0m, in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   2008\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[0;32m-> 2009\u001b[0m \u001b[39mraise\u001b[39;00m _invalid_shape_error(shape, context)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/datathinking.org/lib/python3.11/site-packages/jax/_src/core.py:2027\u001b[0m, in \u001b[0;36m_invalid_shape_error\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[39mif\u001b[39;00m context:\n\u001b[1;32m   2026\u001b[0m   msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mcontext\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 2027\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, Tracer) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(get_aval(x), ShapedArray)\n\u001b[1;32m   2028\u001b[0m        \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(get_aval(x), ConcreteArray) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m shape):\n\u001b[1;32m   2029\u001b[0m   msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf using `jit`, try using `static_argnums` or applying `jit` to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2030\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39msmaller subfunctions.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2031\u001b[0m   \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m shape:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "from jax import random\n",
    "from jax.scipy.special import expit as sigmoid\n",
    "from jax import grad, jit, vmap\n",
    "from jax import lax\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Read parquet file\n",
    "df = pd.read_parquet('./data/datathinking.zulipchat.com/processed/zerver_message.parquet')\n",
    "\n",
    "# Initialize parameters randomly\n",
    "key = random.PRNGKey(0)\n",
    "key, W_key, b_key = random.split(key, 3)\n",
    "beta = random.normal(W_key, (2,))  # Parameter vector \n",
    "beta_0 = random.normal(b_key, ())  # Intercept 0\n",
    "\n",
    "# Assume number of links and length of message are our predictors\n",
    "# For simplicity, let's generate these columns randomly as the actual computation might be more complex\n",
    "df['x1'] = random.randint(key=key, minval=0, maxval=5, shape=df.shape[0])  # Number of links\n",
    "df['x2'] = df['content'].str.len()  # Length of message\n",
    "\n",
    "# Ensure correct data types\n",
    "df = df.astype({\"x1\": 'float32', \"x2\": 'float32', \"has_link\": 'int32'})\n",
    "\n",
    "# Define features and target\n",
    "X = df[['x1', 'x2']].values\n",
    "y = df['has_link'].values\n",
    "\n",
    "# Predict function\n",
    "def predict(beta, beta_0, inputs):\n",
    "    return sigmoid(np.dot(inputs, beta) + beta_0)\n",
    "\n",
    "# Loss function\n",
    "def loss(beta, beta_0, inputs, targets):\n",
    "    preds = predict(beta, beta_0, inputs)\n",
    "    label_probs = preds * targets + (1 - preds) * (1 - targets)\n",
    "    return -np.sum(np.log(label_probs))\n",
    "\n",
    "# Compute gradient of loss function\n",
    "grad_loss = jit(grad(loss, argnums=(0, 1)))\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "for i in range(epochs):\n",
    "    dbeta, dbeta_0 = grad_loss(beta, beta_0, X, y)\n",
    "    beta -= learning_rate * dbeta\n",
    "    beta_0 -= learning_rate * dbeta_0\n",
    "\n",
    "# Print final parameters\n",
    "print(\"beta:\", beta)\n",
    "print(\"beta_0:\", beta_0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datathinking.org",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
